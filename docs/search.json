[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "챗GPT 데이터 과학",
    "section": "",
    "text": "서문",
    "crumbs": [
      "서문"
    ]
  },
  {
    "objectID": "index.html#책의-구성",
    "href": "index.html#책의-구성",
    "title": "챗GPT 데이터 과학",
    "section": "책의 구성",
    "text": "책의 구성",
    "crumbs": [
      "서문"
    ]
  },
  {
    "objectID": "index.html#감사의-글",
    "href": "index.html#감사의-글",
    "title": "챗GPT 데이터 과학",
    "section": "감사의 글",
    "text": "감사의 글\n\n이 책이 탄생할 수 있도록 도움을 주신 여러분께 깊은 감사의 마음을 표합니다.\n공익법인 한국 R 사용자회가 없었다면 데이터 과학분야 챗GPT 시리즈가 세상에 나오지 못했을 것입니다. 한국 R 사용자회의 유충현 회장님, 신종화 사무처장님, 홍성학 감사님, 올해부터 새롭게 공익법인 한국 R 사용자를 이끌어주실 형환희 회장님께 감사드립니다.\n또한 이 책은 2014년 처음 몸담게 된 소프트웨어 카펜트리 그렉 윌슨 박사님과 Python for Informatics 저자인 미시건 대학 찰스 세브란스 교수님을 비롯한 전세계 수많은 익명의 기여자들의 노력과 지원이 있었고, 서울 R 미트업에서 발표해주시고 참여해주신 수많은 분들이 격려와 영감을 주셨기에 가능했습니다.\n이 책이 출간되는데 있어 이들 모든 분들의 도움 없이는 어려웠을 것입니다. 그동안의 관심과 지원에 깊은 감사를 드리며, 이 책이 데이터 과학의 발전과 독자들에게 도움이 될 수 있기를 바라는 마음으로 마무리하겠습니다.\n\n2024년 4월 속초 영금정\n이광춘",
    "crumbs": [
      "서문"
    ]
  },
  {
    "objectID": "ingest_import.html",
    "href": "ingest_import.html",
    "title": "23  텍스트 파일",
    "section": "",
    "text": "23.1 데이터 종류\ngraph TB\n    subgraph 가져오기[\"가져오기(Import)\"]\n        csv[CSV 파일] --&gt; 핸들러\n        스프레드쉬트 --&gt; 핸들러\n        데이터베이스 --&gt; 핸들러\n        웹 --&gt; 핸들러\n\n        핸들러 --&gt; 데이터프레임\n    end\n    \n    classDef modern fill:#fff,stroke:#333,stroke-width:2px,color:#333,font-family:MaruBuri,font-size:12px;\n    classDef emphasize fill:#8CBDE3,stroke:#333,stroke-width:3px,color:#333,font-family:MaruBuri,font-size:15px,font-weight:bold;\n    classDef subgraphStyle fill:#f0f8ff,stroke:#333,stroke-width:2px,color:#333,font-family:MaruBuri,font-size:20px;\n    \n    class csv,스프레드쉬트,데이터베이스,웹,핸들러 modern\n    class 데이터프레임 emphasize\n    class 가져오기 subgraphStyle\n\n\n\n\n그림 23.2: 다양한 데이터 종류",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>텍스트 파일</span>"
    ]
  },
  {
    "objectID": "llm_python.html",
    "href": "llm_python.html",
    "title": "\n27  쿼토 파이썬 환경\n",
    "section": "",
    "text": "아나콘다를 설치하고 conda 가상환경을 설정한다. 가상환경 이름은 envs로 설정하고 데이터 과학, 인공지능을 위한 기본 파이썬 패키지도 가상환경 안에 설치한다.\n$ conda create --prefix ./envs python=3.11 numpy seaborn pandas matplotlib scikit-learn transformers\n$ conda activate ./envs\n$ which python\n파이썬(python.exe)를 R 환경에 연결시키기 위해 정확한 경로명을 reticulate::conda_list() 함수로 확인한다.\n\nreticulate::conda_list()\n\n\nusethis::edit_r_profile()\n\nusethis::edit_r_profile() 명령어를 통해 .Rprofile 파일을 열고 아래 내용을 추가한다.\nSys.setenv(RETICULATE_PYTHON=\"C:\\\\chatGPT4ds\\\\envs\\\\python.exe\")\n\nlibrary(reticulate)\npy_config()\n\npython:         D:/tcs/chatGPT4ds/envs/python.exe\nlibpython:      D:/tcs/chatGPT4ds/envs/python311.dll\npythonhome:     D:/tcs/chatGPT4ds/envs\nversion:        3.11.7 | packaged by Anaconda, Inc. | (main, Dec 15 2023, 18:05:47) [MSC v.1916 64 bit (AMD64)]\nArchitecture:   64bit\nnumpy:          D:/tcs/chatGPT4ds/envs/Lib/site-packages/numpy\nnumpy_version:  1.26.3\n\nNOTE: Python version was forced by RETICULATE_PYTHON\n\n\n\n28 감성분석\n\nfrom transformers import pipeline\n\nprompt = \"The ambience was good, food was quite good.\"\n\nclassifier = pipeline(\"text-classification\", \n                      model='nlptown/bert-base-multilingual-uncased-sentiment')\n\nprediction = classifier(prompt)\nprint(prediction)\n\n[{'label': '4 stars', 'score': 0.5752392411231995}]",
    "crumbs": [
      "**8부** 챗GPT",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>쿼토 파이썬 환경</span>"
    ]
  },
  {
    "objectID": "local_llm.html",
    "href": "local_llm.html",
    "title": "28  오라마 설치",
    "section": "",
    "text": "Ollama 설치\nstatkclee@dl:/mnt/d/tcs/chatGPT4ds/llm$ curl https://ollama.ai/install.sh | sh\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0&gt;&gt;&gt; Downloading ollama...\n100  8422    0  8422    0     0  18348      0 --:--:-- --:--:-- --:--:-- 18348\n######################################################################## 100.0%##O=#  #                                 ######################################################################## 100.0%\n&gt;&gt;&gt; Installing ollama to /usr/local/bin...\n&gt;&gt;&gt; Adding ollama user to render group...\n&gt;&gt;&gt; Adding current user to ollama group...\n&gt;&gt;&gt; Creating ollama systemd service...\n&gt;&gt;&gt; NVIDIA GPU installed.\n&gt;&gt;&gt; The Ollama API is now available at 0.0.0.0:11434.\n&gt;&gt;&gt; Install complete. Run \"ollama\" from the command line.",
    "crumbs": [
      "**8부** 챗GPT",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>오라마 설치</span>"
    ]
  },
  {
    "objectID": "lang_gpt.html",
    "href": "lang_gpt.html",
    "title": "29  챗GPT 자연어",
    "section": "",
    "text": "30 챗GPT 시대 데이터 분석\n\nOpenAI 챗GPT Code Interpreter 플러그인\n노터블(Notable): EDA & ETL Made Easy (SQL, Python, & R)\n오픈소스 GPT-Code UI\nR\n\nRTutor.ai, GitHub 저장소\nhttps://chatlize.ai/\n\n\n\n\n31 Code Interpreter\n\n1단계2단계3단계4단계5단계 (데이터+프롬프트)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n32 Notable.ai\n\n\n33 심슨 패러독스\n\n챗GPT Code Interpreter : 채팅 이력\nJupyter Notebook 다운로드: penguin_analysis.ipynb\npenguin_analysis.ipynb → penguin_analysis.qmd\n\n명령어: $ quarto convert penguin_analysis.ipynb\n\n쿼토 컴파일: 바로가기",
    "crumbs": [
      "**8부** 챗GPT",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>챗GPT 자연어</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "참고문헌",
    "section": "",
    "text": "Abu-Mostafa, Yaser S, Malik Magdon-Ismail, and Hsuan-Tien Lin. 2012.\nLearning from Data. Vol. 4. AMLBook New York.\n\n\nBecker, Richard. 2018. The New s Language. CRC Press.\n\n\nCaffo, Brian. 2015. Advanced Linear Models for Data Science.\nLeanpub.\n\n\nChambers, J. M., and T. J. Hastie. 1992. Statistical Models in\ns. London: Chapman & Hall.\n\n\nDibia, Victor. 2023. “LIDA: A Tool for Automatic\nGeneration of Grammar-Agnostic Visualizations and Infographics Using\nLarge Language Models.” In Proceedings of the 61st Annual\nMeeting of the Association for Computational Linguistics (Volume 3:\nSystem Demonstrations), edited by Danushka Bollegala, Ruihong\nHuang, and Alan Ritter, 113–26. Toronto, Canada: Association for\nComputational Linguistics. https://doi.org/10.18653/v1/2023.acl-demo.11.\n\n\nFriendly, Michael. 2023. HistData: Data Sets from the History of\nStatistics and Data Visualization.\n\n\nPebesma, Edzer, and Roger Bivand. 2023. Spatial\nData Science: With Applications in R. Chapman; Hall/CRC. https://doi.org/10.1201/9780429459016.\n\n\nPebesma, Edzer, Wolfgang Wagner, Jan Verbesselt, Erwin Goor, Christian\nBriese, and Markus Neteler. 2016. “OpenEO: A GDAL for Earth\nObservation Analytics.” 2016. https://r-spatial.org/2016/11/29/openeo.html.\n\n\nStack\", \"Enigma of the. 2023. “The Future of Data Analysis: 10\nChatGPT Prompts You Should Start Using Today.”\nMedium.com, December. https://medium.com/ai-in-plain-english/the-future-of-data-analysis-10-chatgpt-prompts-you-should-start-using-today-39734b701e43.\n\n\nWickham, Hadley. 2011. “The Split-Apply-Combine Strategy for Data\nAnalysis.” Journal of Statistical Software 40: 1–29.\n\n\n이광춘. 2023. “공간정보의 역사 및 공간정보 처리기법.”\n프롭빅스(PROPBIX), no. 13 (September). http://www.kahps.org/.",
    "crumbs": [
      "참고문헌"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  들어가며",
    "section": "",
    "text": "1.1 좋은 소프트웨어 작성법\n좋은 소프트웨어를 작성하려면,\n위의 원칙을 지키면 다른 동료 연구자들과 미래의 자신에게 읽기 쉽고, 이해하기 쉽고, 확장 가능한 코드를 선물할 수 있을 것이다.",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>들어가며</span>"
    ]
  },
  {
    "objectID": "intro.html#좋은-소프트웨어-작성법",
    "href": "intro.html#좋은-소프트웨어-작성법",
    "title": "1  들어가며",
    "section": "",
    "text": "프로젝트를 적절히 구조화하고,\n필요한 사항은 문서화하고,\n복잡한 문제는 작은 모듈로 나누어 해결하고,\n코드 작동을 검증하는 테스트를 만들고,\n반복되는 코드는 함수로 묶어서 처리하고,\n일관된 코딩 스타일을 고수해야 한다.\n\n\n\n1.1.1 프로젝트 폴더 구조화\n하위 폴더를 코드, 매뉴얼, 데이터, 바이너리, 출력 그래프 등으로 구분하여 프로젝트 폴더를 구조화하고, 잘 조직화하고, 깔끔하게 만든다. 완전 수작업으로 할 수도 있고, RStudio New Project 기능을 활용하거나 ProjectTemplate 같은 패키지를 사용한다.\n\n\n\n\n\n\nProjectTemplate - 가능한 해결책\n\n\n\n프로젝트 관리를 자동화하는 한 방식은 제3자 패키지, ProjectTemplate을 설치하는 것이다. 해당 패키지는 프로젝트 관리에 대한 이상적인 디렉토리 구조를 설정해 놓는다. 패키지가 자동으로 분석 파이프라인/작업 흐름을 구성해서 구조화해 놓는다. RStudio 기본 설정된 프로젝트 관리 기능과 Git을 섞어 사용하면, 작업을 기록할 뿐만 아니라, 동료 연구원과 작업 산출물을 공유할 수 있게 한다.\n\n\nProjectTemplate을 설치한다.\n라이브러리를 불러 적재한다.\n프로젝트를 초기화한다.\n\n\ninstall.packages(\"ProjectTemplate\")\n\nlibrary(ProjectTemplate)\ncreate.project(\"../my_project\", merge.strategy = \"allow.non.conflict\")\n\nProjectTemplate과 기능에 대한 자세한 사항은 ProjectTemplate 홈페이지를 방문한다.\n\n\n\n1.1.2 가독성 높은 코드 생성\n코드 작성에 있어 가장 중요한 부분은 코드를 가독성 있고 이해할 수 있게 작성하는 것이다. 누군가 여러분이 작성한 코드를 보고 무슨 작업을 수행하는지 이해할 수 있어야 한다. 흔히 누군가는 6개월 후에 바로 당신이 될 수 있고, 만약 그렇게 작성하지 않았다면 과거 자기 자신을 분명히 저주하게 될 것이다.\n\n1.1.3 문서화\n처음 코드를 작성할 때, 주석은 명령어가 무엇을 수행하는지 기술한다. 왜냐하면, 여전히 학습 중이라 개념을 명확히 하고, 나중에 다시 상기하는 데 도움이 되기 때문이다. 하지만, 이러한 주석은 나중에 작성한 코드가 어떤 문제를 해결하고자 하는지 기억하지 못하면 그다지 도움이 되지 않는다.\n왜(why) 문제를 해결하려고 하는지, 그리고 어떤(what) 문제인지 전달하는 주석을 달려고 노력한다. 어떻게(how)는 그 다음에 온다. 정말 걱정할 필요가 없는 사항은 구체적인 구현이다.\n\n1.1.4 코드 모듈화\n소프트웨어 카펜트리에서 추천하는 것은 작성한 함수를 분석 스크립트와 구별해서 별도 파일에 저장하는 것이다. 프로젝트 R세션을 열 때, source 함수로 불러올 수 있게 별도 파일로 저장한다.\n분석 스크립트를 깔끔하게 유지하고, 유용한 함수 저장소를 프로젝트 분석 스크립트에 적재할 수 있게 함으로써 이러한 접근법이 깔끔하다. 또한 관련된 함수를 쉽게 그룹화한다.\n\n1.1.5 문제를 작게 분해\n처음 시작할 때, 문제 해결과 함수 작성은 어마어마한 작업이고, 코드를 쪼개는 것도 힘들다. 문제를 소화 가능한 덩어리로 쪼개고, 나중에 구현에 관한 구체적인 사항을 걱정한다. 해결책을 코드로 작성할 수 있는 지점까지 문제를 더 작게 그리고 더 작은 함수로 계속 쪼개 나간다. 그리고 나서 다시 거꾸로 조립해서 만들어 낸다.\n\n1.1.6 코드 테스트\n작성한 코드가 올바른 작업을 수행하도록 만든다. 작성한 함수를 테스트해서 확실히 동작하게 만든다.\n\n1.1.7 복붙 금지\n복붙은 코드를 작성하는 데 있어서 가장 나쁜 방법이다. 함수는 프로젝트 내부에서 재사용을 쉽게 한다. 프로젝트를 통해서 유사한 코드 라인 덩어리를 보게 되면, 대체로 함수로 옮겨져야 하는 대상을 찾은 것이다.\n연산 작업이 연속된 함수를 통해 실행되면, 프로젝트는 모듈로 만들기 쉽고, 변경하기 쉽다. 항상 특정한 입력값을 넣으면 특정한 출력값이 나오는 경우에 특히 그렇다.\n\n1.1.8 스타일 고집\n코드에 일관된 스타일을 지킨다. 이것은 코드를 읽고 이해하는 데 도움이 된다.\n\n1.1.9 코드 스타일과 가독성\n일관된 코딩 스타일은 가독성을 높이고 버그를 최소화한다. R 커뮤니티에서 가장 널리 사용되는 스타일 가이드 중 하나는 해들리 위컴 스타일 가이드다. Google의 R 스타일 가이드도 널리 사용된다.\n일관된 스타일에 프로젝트를 고수하면, 다른 사람들이 코드를 더 쉽게 읽고 확장할 수 있다. RStudio의 코드 정리 기능을 활용하여 코드 스타일을 자동으로 적용할 수도 있다.\n\n1.1.10 핵심은 일관성\n함수 이름 붙이기, 코드 들여쓰기, 주석 달기 등 코딩 스타일의 어떤 요소든 한번 선택하면 이후로도 꾸준히 같은 스타일을 고수해야 한다. 코드 작성자에게는 편한 스타일이 좋지만, 팀 단위로 협업한다면 팀에서 합의한 코딩 스타일을 따르는 것이 바람직하다.",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>들어가며</span>"
    ]
  },
  {
    "objectID": "intro_tidyverse.html",
    "href": "intro_tidyverse.html",
    "title": "2  데이터 사이언스 운영체제",
    "section": "",
    "text": "3 패러다임의 변화 1\n정보를 잃지 않고 압축하거나 최대한 많은 정보를 추출하고자 하는 노력으로 통계학 이론들이 많이 활용되었지만, 최근에는 기계학습/딥러닝을 통해 다양한 통계 모형이 이론적인 면뿐만 아니라 실무에서도 많이 사용되고 있다. 이런 점에서 만 개가 넘는 R 패키지가 개발되어 활용된다는 점은 긍정적이지만, 각자의 설계 원칙에 맞춰 제각기 개발되고, 손을 바꿔 여러 다른 사람들이 유지보수하게 되면서 초기 세워진 설계 원칙과 철학이 많이 무너진 점이 지속 가능한 데이터 사이언스 발전을 가로막고 있는 커다란 장애물로 떠올랐다. 이를 인지한 데이터 과학자는 다수 존재하지만, 이를 체계적으로 실제로 활용할 수 있도록 아마도 가장 크게 기여한 분을 꼽으라면 다들 “해들리 위컴”(Hadley Wickham)을 꼽는 데 주저하지 않을 것이다. tidyverse는 수많은 기여자들의 도움을 받아 해들리 위캄이 오랜 동안 나름대로의 방식으로 체계화시킨 것을 확대 발전시킨 것으로 데이터 사이언스를 체계적으로 집대성하였다는 평가를 받고 있다. 특히, 데이터 과학자 및 실무자에게 큰 도움을 주었는데, 어떻게 보면 기존 SAS/SPSS/미니탭과 같은 상용 패키지 중심에서 R을 중심으로 한 오픈소스 소프트웨어로 흐름을 바꾸었다고 볼 수 있다. 데이터를 다루려면 컴퓨터가 필요하고 컴퓨터와 대화하기 위해서는 언어가 필요한데, 다행히 통계학에서는 R 언어가 1990년대 초반 개발되자마자 오픈소스로 공개되어 자연스럽게 통계학 전공자들이 오픈소스 소프트웨어에 친숙하게 되는 계기가 되었다.\n마이크로소프트 창업자 빌 게이츠가 소프트웨어 상업화 모델로 큰 성공을 거두면서 기존 IBM이 만들어 놓았던 생태계가 크게 변화했지만, 지나친 소프트웨어 상업화에 대한 반발로 리차드 스톨만이 씨를 뿌리고 리누스 토발즈가 튼튼한 뿌리를 내린 리눅스 운영체제, 인터넷의 보급으로 오픈소스 소프트웨어(Open Source Software)에 대한 확산, 개방과 공유를 가치로 하는 개발자 특유의 문화를 기반으로 이제 대세는 오픈소스 소프트웨어가 되었다. 이러한 소프트웨어에 대한 인식의 전환은 GNU 선언문에 잘 표현되어 있다.\n데이터를 많이 다루는 통계학도 소프트웨어 패러다임의 변화에 맞춰 진화해 왔다. SAS/SPSS/미니탭으로 대표되는 통계 패키지와 더불어 가우스/매트랩/매스매티카를 필두로 한 고급 상용 소프트웨어가 한 시대를 풍미했다면, 이제는 R과 파이썬으로 대표되는 오픈소스 소프트웨어가 그 빈자리를 급격히 채워 나가고 있다. 이러한 변화를 직감했던지 해들리 위컴은 2017년 11월 13일 Tidyverse 선언문(Tidy Tools Manifesto)을 직접 작성하여 웹사이트에 공개하였다.\n데이터 사이언스 언어 R을 사용해서 산적한 과제를 해결해 나가면서 쌓인 여러 지적 자산을 패키지로 개발하여 공개하였고, 이를 통칭하여 과거 Hadleyverse로 불렀다. 이유는 dplyr, ggplot2 패키지를 해들리 위컴이 제작했고, 데이터 사이언스 문제를 풀려고 하면 해들리 위컴이 제작한 패키지를 조합해서 접근해야 수월히 풀 수 있었기 때문이다. 하지만, 오픈소스 소프트웨어 개발은 한 사람의 노력으로만 가능한 것이 아니고, 전 세계 수많은 개발자와 사용자의 노력으로 이뤄낸 성과이기에 이를 tidyverse라는 명칭으로 통일하면서 데이터 사이언스 운영체제와 같은 역할과 위상을 가지게 되었다.",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>데이터 사이언스 운영체제</span>"
    ]
  },
  {
    "objectID": "intro_tidyverse.html#tidyverse-workflow",
    "href": "intro_tidyverse.html#tidyverse-workflow",
    "title": "2  데이터 사이언스 운영체제",
    "section": "4.1 tidyverse 작업 흐름",
    "text": "4.1 tidyverse 작업 흐름\ntidyverse의 핵심적인 내용은 다양한 형태의 데이터를 가져와서 최종 산출물을 사람과 기계가 커뮤니케이션할 수 있는 형태로 제작하는 과정을 추상화한 것으로 이해할 수 있다. 시각화(Visualization)는 데이터에 대한 통찰력(insight)과 탄성, 놀라움을 줄 수 있지만, 확장성(Scalability) 측면에서는 한계가 명확히 존재하게 되는데 이는 사람이 작업 흐름 루프에 포함되기 때문이다. 반대로 모형(Model)은 자동화와 확장성에는 장점이 있지만, 주어진 모형 틀 안에서만 이뤄지기 때문에 통찰력, 놀라움, 탄성을 주지는 못하는 아쉬움이 있다. 따라서, tidyverse는 시각화와 모형을 통해 통찰력과 함께 자동화에 대한 부분도 충분히 반영한 체계적인 작업 흐름을 제시하고 있는데, 이를 관통하는 핵심적인 개념이 파이프(pipe)로 이미 이런 개념은 유닉스 파이프 연산자를 통해 검증되었다.\n\n\n\nTidyverse 데이터 사이언스 작업흐름",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>데이터 사이언스 운영체제</span>"
    ]
  },
  {
    "objectID": "intro_tidyverse.html#tidy-data",
    "href": "intro_tidyverse.html#tidy-data",
    "title": "2  데이터 사이언스 운영체제",
    "section": "4.2 깔끔한 데이터",
    "text": "4.2 깔끔한 데이터\n기존 소프트웨어와 다르게 tidyverse는 데이터를 중심으로 다루기 때문에 깔끔한 데이터(tidy data)에 대한 이해도 추가로 필요로 한다. 깔끔한 데이터(tidy data)의 정의는 데이터를 통해 정보를 추출하고, 인사이트를 도출하기 위해서 시각화를 하고, 데이터를 모형으로 자동화하고, 커뮤니케이션을 위한 웹앱을 개발하고 발표 보고서를 작성할 때 수월한 자료구조를 갖는 데이터를 의미한다. 엄밀한 의미로 깔끔한 데이터를 전산학 데이터베이스 이론을 가져와서 설명할 수도 있지만, 비전산 전공자의 관점에서 풀어보자면 깔끔한 데이터가 준비되면 정제작업과 변형, 모형 개발, 시각화, 보고서 작성을 원활히 할 수 있는 반면 엉망진창인 데이터(messy data)는 그렇지 않은 데이터로 볼 수 있다.\n깔끔한 데이터는 특정한 구조를 갖추고 있는데 변수는 열(column)이고, 관측점은 행(row)이며, 관측 단위에 대한 형태는 데이터셋 즉, 테이블(table)로 구성된다.\n깔끔한 데이터 원칙은 전산학 코드(Codd) 박사의 관계대수(Relational Algebra)와 깊은 관련이 있어, 통계학 전공자들은 해당 데이터셋에서 관측점과 변수를 각각 식별하는 작업을 쉽게 생각하지만, 일반적으로 변수와 관측점을 정확하게 정의하는 것이 보통 어려운 것은 아니다. 따라서, 행과 행보다는 변수 간 기능적 관계(functional relationship)를 기술하는 것이 더 쉽고, 칼럼 그룹 집단 간 비교보다 관측점 그룹 집단 사이 비교를 하는 것이 더 쉽다.\n깔끔한 데이터(tidy data)는 데이터셋의 의미를 구조에 매칭하는 표준적인 방식으로 이와 같이 데이터가 구조화되면, 데이터 분석, 조작, 시각화, 모형 작업을 수월히 진행할 수 있다.\n\n각 변수가 칼럼이 된다.\n각 관측점은 행이 된다.\n관측 단위에 대한 형태는 테이블로 구성한다.\n\n\n\n\n저장 구분\n의미\n\n\n\n\n테이블/파일(table/file)\n데이터셋 (dataset)\n\n\n행(row)\n관측점 (observation)\n\n\n열(column)\n변수 (variable)\n\n\n\n깔끔하지 않는 데이터(messy data)는 위와는 다른 형태의 데이터를 지칭한다. 전산학에서 말하는 코드 제3 정규형이지만, 통계적 언어로 다시 표현한 것이다. 또한, 깔끔한 데이터는 R같은 벡터화 프로그래밍 언어에 특히 잘 맞는다. 왜냐하면 동일한 관측점에 대한 서로 다른 변수 값이 항상 짝으로 매칭되는 것을 보장하기 때문이다.\n시각화와 모형을 새로 개발하는 데 별도 자료구조(data structure)를 다시 창조하는 대신에 가능하면 기존 자료구조를 재사용하는 것을 원칙으로 삼고 있다. ggplot2, dplyr, tidyr을 포함한 대다수 R 패키지는 칼럼에 변수, 행에 관측점을 갖는 직사각형 형태 데이터셋을 가정하고 있다. 그리고, 일부 패키지는 특정한 변수 자료형에 집중한다. stringr은 문자열, lubridate는 날짜/시간, forcats는 요인 자료형에 집중하고 있지만 모두 기존 자료구조 재사용을 염두에 두고 있는 것도 사실이다.",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>데이터 사이언스 운영체제</span>"
    ]
  },
  {
    "objectID": "intro_tidyverse.html#tidyverse-functional-programming",
    "href": "intro_tidyverse.html#tidyverse-functional-programming",
    "title": "2  데이터 사이언스 운영체제",
    "section": "4.3 함수형 프로그래밍",
    "text": "4.3 함수형 프로그래밍\n복잡한 문제를 해결하는 강력한 전략은 레고 블록처럼 다수의 간단한 조각으로 나누고 이를 조합하는 것이다. 단, 각 조각은 격리되어 쉽게 파악되며, 다른 조각과 조합할 수 있는 표준 위에서 성립되어야 한다. tidyverse 밑바탕에는 이런 전략이 파이프 연산자를 통해 구현되어 있고, 파이프 연산자(예를 들어, %&gt;%)로 단순한 함수를 조합하여 시스템 전체의 힘을 극대화시킨다.\n이를 위해서는 무엇보다 레고 블록 같은 패키지 혹은 함수가 동일한 인터페이스 표준을 준수해야만 한다. %&gt;% 연산자를 통해 많은 패키지에 걸쳐 동작되도록 만드려면, 함수를 작성할 때 다음 원칙을 준수하여 작성하면 된다.\n\n함수를 가능하면 단순하게 작성한다. 일반적으로 각 함수는 한 가지 작업을 매우 잘해야 되고, 한 문장으로 함수 존재 목적을 기술할 수 있어야 한다.\n변형(transformation)과 부작용(side-effect)을 섞지 말아야 한다. 함수가 객체를 반환하거나, 부작용을 일으키는 둘 중 하나만 동작하게 만든다.\n함수명은 동사로 작성해야 한다. 하지만, 다수의 함수가 동일한 동사를 사용하는 경우는 예외로 한다. 예를 들어 modify, add, compute 등을 들 수 있다. 이런 경우 반복되는 동사가 중복되지 않도록 명사에 집중한다. ggplot2가 좋은 예인데, 기존 플롯에 좌표, 점, 범례 등 거의 모든 함수가 추가되기 때문이다.\n\nR은 데이터를 위해 개발된 함수형 언어를 근본에 두고 있지만, 객체 지향 언어(OOP)나 다른 언어 패러다임과 싸우려고 하지 말고 적극적으로 받아들이라고 충고하고 있는데, 이것이 의미하는 바는 다음과 같다.\n\n상태 불변 객체: 작성된 코드에 대한 추론이 쉬워진다.\nS3, S4에서 제공하는 제네릭 함수: 상태 변형 가능한 상태가 필요하다면, 파이프 내부에서 구현한다.\nfor 루프를 추상화한 도구: apply 함수 가족과 purrr 맵(map) 함수\n\n데이터 사이언스에서 병목점으로 문제가 발생되는 곳은 공통적으로 컴퓨터 실행 시간(computing time)이 아니라 사람의 생각(thinking time)의 시간이다. 따라서, 함수명을 작성할 때 생각이 잘 연상되는 이름으로 작명하고 시간을 적절히 안분하고, 명시적이며 긴 명칭을 변수명, 함수명, 객체명에 사용하고, 짧은 명칭은 가장 중요한 이름으로 아껴서 사용한다. RStudio 소스 편집기의 자동 완성 기능을 사용하는 경우 접두어가 접미어보다 왜 중요한지 알 수 있고, stringr, xml2, rvest 패키지를 살펴보면 접두어에 일관된 명칭을 부여한 장점을 알 수 있다.",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>데이터 사이언스 운영체제</span>"
    ]
  },
  {
    "objectID": "intro_tidyverse.html#footnotes",
    "href": "intro_tidyverse.html#footnotes",
    "title": "2  데이터 사이언스 운영체제",
    "section": "",
    "text": "Hadley Wickham (2017-11-13), “The tidy tools manifesto”↩︎",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>데이터 사이언스 운영체제</span>"
    ]
  },
  {
    "objectID": "intro_whole_game.html",
    "href": "intro_whole_game.html",
    "title": "\n3  데이터 과학 맛보기\n",
    "section": "",
    "text": "3.1 나이팅게일 신화탄생",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 과학 맛보기</span>"
    ]
  },
  {
    "objectID": "intro_whole_game.html#나이팅게일-신화탄생",
    "href": "intro_whole_game.html#나이팅게일-신화탄생",
    "title": "\n3  데이터 과학 맛보기\n",
    "section": "",
    "text": "3.1.1 배경\n크림 전쟁은 1853년부터 1856년까지 일어난 큰 전쟁이었다. 한쪽에는 러시아, 반면 다른 한쪽에는 영국, 프랑스, 오스만 제국 (현대 투르키에), 그리고 나중에 사르디니아 (현대 이탈리아의 일부)가 동맹을 구성하여 전쟁을 치뤘다. 전쟁이 바로 시작된 이유는 러시아가 오스만 제국 내 정교회 신자들을 보호하려 하려는 명분을 내세웠지만, 사실 더많은 영토를 차지하기 위함이였다. 양측간 전쟁은 흑해를 두고 남하하는 러시아에 맞서 동맹군이 크림반도에서 발생하여 “크림전쟁”(Crimean War)으로 불린다. 영화로 소개된 경기병대의 돌격 (“Charge of the Light Brigade”), 영국 간호사 플로렌스 나이팅게일의 활약, 전신과 철도의 본격적인 도입으로 큰 의미를 갖는 전쟁이기도 하다. 많은 전투와 많은 사람들이 죽은 후, 1856년 파리 조약으로 전쟁은 마무리되어, 러시아 확장은 잠시 멈추게 돼었고, 오스만 제국도 한숨 돌린 계기가 되었다.\n크림 전쟁 중 스쿠타리 막사는 투루키에 스쿠타리 병원(Scutari Hospital, Turkey)은 영국 군 병원으로 개조되었다. 크림전쟁에서 부상을 당한 수많은 병사가 치료를 위해 이곳으로 보내졌지만, 병자와 부상병들을 감당할 수 있도록 설계되지 않았고 제대로된 역할도 수행하지 못했다. 1854년 나이팅게일이 간호사 일행과 함께 도착했을 때, 비위생적인 환경과 고통받는 병사들을 보고 경악했다. 나이팅게일의 스쿠타리 병원에서 경험은 병원과 의료 서비스를 개선하여 이와 같은 고통과 비극이 재발하지 않도록 향후 프로젝트의 중요한 동기와 방향이 되었다.\n\n\n스쿠타리 병원의 한 병동 석판화 그림 (William Simpson)\n\n환자의 사망율을 42%에서 2%로 낮추고 집중치료실(ICU)을 설치하여 상태가 중한 환자를 격리하여 집중관리하는 등 근대적인 간호체계를 수립하는 데 기여하였다.\n\n3.1.2 원본 데이터\n크림 전쟁 중 스쿠타리 막사는 투루키에 스쿠타리 병원에서 몇년간에 걸쳐 수작업으로 종이에 분석가능한 형태의 자료를 만들어내는 것은 결코 쉬운 작업이 아니다.\n\n\n원본 데이터\n\n\n3.1.3 그래프 진화\n출처: How Florence Nightingale Changed Data Visualization Forever - The celebrated nurse improved public health through her groundbreaking use of graphic storytelling\n복잡한 논거를 제시하는 대신 구체적인 주장에 데이터 시각화와 데이터 스토리텔링(Storytelling)을 통해 청중에 한걸음 더 다가섰다. 나이팅게일의 스토리텔링은 열악한 위생 상태와 과밀로 인해 불필요한 죽음이 얼마나 많이 발생하는지 이해하기 쉬운 비교를 통해 이야기를 구성해서 설득해 나갔다. 예를 들어, 군대 사망률을 민간인 사망률(유사한 환경의 맨체스터)과 비교하는 프레임을 제시하고, 군대 막사에서 생활하는 평시 병사들이 비슷한 연령대 민간인 남성보다 더 높은 비율로 사망하는 것을 제시했다. 이를 통해, 데이터가 보여주는 현실을 부정할 수 없게 만들었고, 군대 행정에 극적인 개혁을 이끌어냈다.\n\n\n\n\n\n\n\n\n\n(a) 막대그래프\n\n\n\n\n\n\n\n\n\n(b) 맨체스터 사망\n\n\n\n\n\n\n\n\n\n(c) 빅토리아 여왕 보고(I)\n\n\n\n\n\n\n\n\n\n(d) 빅토리아 여왕 보고(II)\n\n\n\n\n\n\n\n\n\n(e) 빅토리아 여왕 보고(III)\n\n\n\n\n\n\n그림 3.1: 나이팅게일 그래프 진화과정\n\n\n\n3.1.4 설득\n나이팅게일은 크림 전쟁 중 병원에서의 위생 문제와 관련된 데이터를 수집하고 분석하여 그 결과를 시각화했고, 병원에서의 사망 원인 중 대부분이 감염성 질병으로 인한 것을 발견했다. 이러한 감염성 질병은 부적절한 위생 조건과 밀접한 관련이 있음을 확인했다.\n나이팅게일은 병원의 위생 상태를 개선을 통해 수많은 생명을 구할 수 있다는 사실을 확인했고 연구결과와 권장 사항을 다양한 영국 정부부처에 제출했고, 특히 1858년에 영국의 장관들에게 보고서를 제출했다. 이를 통해서 군 병원의 위생 조건을 개선하는 데 큰 영향을 미쳤다.\n\n\n나이팅게일과 빅토리아 여왕\n\n\n3.1.5 성과와 영향\n나이팅게일 캠페인이 민간 공중보건에 미친 가장 큰 영향은 실현되기까지 오랜 기간에 걸쳐 다각도로 검토되었고, 마침내 1875년 영국 공중보건법(British Public Health Act)에 법제화되었다. 이 법에는 잘 정비된 하수도, 깨끗한 수돗물, 건축법 규제 등의 요건이 담겨있다. 질병에 대한 면역력을 강화하는 백신과 농작물 수확량을 획기적으로 늘리는 인공비료 개발과 함께 이 제도적인 노력으로 평균 수명을 두 배로 늘리는 원동력이 되었다.",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 과학 맛보기</span>"
    ]
  },
  {
    "objectID": "intro_whole_game.html#작업과정",
    "href": "intro_whole_game.html#작업과정",
    "title": "\n3  데이터 과학 맛보기\n",
    "section": "\n3.2 작업과정",
    "text": "3.2 작업과정\n\n3.2.1 디지털 데이터\nrladies/spain_nightingale GitHub 저장소에서 엑셀 형태로 된 데이터를 가져와서 전처리할 수 있다.\n\nlibrary(tidyverse)\nlibrary(readxl)\n\ndeath_raw &lt;- read_excel(\"data/datos_florence.xlsx\", sheet = \"Sheet1\", skip = 1)\n\ndeath_tbl &lt;- death_raw |&gt; \n  janitor::clean_names() |&gt; \n  set_names(c(\"Month\", \"Army\", \"Disease\", \"Wounds\", \"Other\", \"Disease.rate\", \"Wounds.rate\", \"Other.rate\")) |&gt; \n  mutate(Date = lubridate::my(Month)) |&gt; \n  separate(Month, into = c(\"Month\", \"Year\"), sep = \" |_\") |&gt; \n  select(Date, Month, Year, everything()) \n\ndeath_tbl\n#&gt; # A tibble: 24 × 10\n#&gt;    Date       Month Year   Army Disease Wounds Other Disease.rate Wounds.rate\n#&gt;    &lt;date&gt;     &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n#&gt;  1 1854-04-01 Apr   1854   8571       1      0     5          1.4         0  \n#&gt;  2 1854-05-01 May   1854  23333      12      0     9          6.2         0  \n#&gt;  3 1854-06-01 Jun   1854  28333      11      0     6          4.7         0  \n#&gt;  4 1854-07-01 Jul   1854  28722     359      0    23        150           0  \n#&gt;  5 1854-08-01 Aug   1854  30246     828      1    30        328.          0.4\n#&gt;  6 1854-09-01 Sep   1854  30290     788     81    70        312.         32.1\n#&gt;  7 1854-10-01 Oct   1854  30643     503    132   128        197          51.7\n#&gt;  8 1854-11-01 Nov   1854  29736     844    287   106        341.        116. \n#&gt;  9 1854-12-01 Dec   1854  32779    1725    114   131        632.         41.7\n#&gt; 10 1855-01-01 Jan   1855  32393    2761     83   324       1023.         30.7\n#&gt; # ℹ 14 more rows\n#&gt; # ℹ 1 more variable: Other.rate &lt;dbl&gt;\n\nHistDate 패키지에 동일한 데이터셋이 잘 정제되어 있어 이를 바로 활용해도 좋다.\n\nlibrary(HistData)\n\nHistData::Nightingale |&gt; \n  as_tibble()\n#&gt; # A tibble: 24 × 10\n#&gt;    Date       Month  Year  Army Disease Wounds Other Disease.rate Wounds.rate\n#&gt;    &lt;date&gt;     &lt;ord&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;  &lt;int&gt; &lt;int&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n#&gt;  1 1854-04-01 Apr    1854  8571       1      0     5          1.4         0  \n#&gt;  2 1854-05-01 May    1854 23333      12      0     9          6.2         0  \n#&gt;  3 1854-06-01 Jun    1854 28333      11      0     6          4.7         0  \n#&gt;  4 1854-07-01 Jul    1854 28722     359      0    23        150           0  \n#&gt;  5 1854-08-01 Aug    1854 30246     828      1    30        328.          0.4\n#&gt;  6 1854-09-01 Sep    1854 30290     788     81    70        312.         32.1\n#&gt;  7 1854-10-01 Oct    1854 30643     503    132   128        197          51.7\n#&gt;  8 1854-11-01 Nov    1854 29736     844    287   106        341.        116. \n#&gt;  9 1854-12-01 Dec    1854 32779    1725    114   131        632.         41.7\n#&gt; 10 1855-01-01 Jan    1855 32393    2761     83   324       1023.         30.7\n#&gt; # ℹ 14 more rows\n#&gt; # ℹ 1 more variable: Other.rate &lt;dbl&gt;\n\n\n3.2.2 데이터와 사투\n앞서 준비한 death_tbl 데이터프레임에서 사망 관련 데이터를 처리하고 시각화하기 위한 전처리를 수행하여 시각화를 위한 준비작업을 수행한다. 먼저 Date, Disease.rate, Wounds.rate, Other.rate 칼럼을 선택하고, pivot_longer 함수를 사용해 시각화에 적합한 데이터로 재구조화한다. str_replace_all 함수를 사용하여 칼럼 이름에서 “.rate”를 제거하고, ifelse 함수를 이용해 날짜를 기준으로 나이팅게일 팀이 준비한 방식을 적용하기 전과후 “이전”과 “이후”로 체제로 구분한다. factor 함수를 사용하여 범주 순서를 정의하고, 마지막으로 month 함수를 이용해 날짜에서 해당 월을 추출하고 death_viz에 저장한다.\n\ndeath_viz &lt;- death_tbl %&gt;% \n  select(Date, Disease.rate, Wounds.rate, Other.rate) %&gt;% \n  pivot_longer(-Date, names_to = \"사망원인\", values_to = \"사망자수\") |&gt; \n  mutate(사망원인 = str_replace_all(사망원인, \"\\\\.rate\", \"\"), \n         체제 = ifelse(Date &lt;= as.Date(\"1855-03-01\"), \"조치이전\", \"조치이후\")) %&gt;% \n  mutate(체제 = factor(체제, levels = c(\"조치이전\", \"조치이후\"))) %&gt;%  \n  mutate(해당월 = month(Date, label = TRUE, abbr = TRUE)) |&gt; \n  mutate(사망원인 = case_when(사망원인 == \"Disease\" ~ \"질병\",\n                              사망원인 == \"Wounds\" ~ \"부상\",\n                              사망원인 == \"Other\" ~ \"기타\")) |&gt; \n  mutate(사망원인 = factor(사망원인, levels = c(\"질병\", \"부상\", \"기타\")))\n\ndeath_viz\n#&gt; # A tibble: 72 × 5\n#&gt;    Date       사망원인 사망자수 체제     해당월\n#&gt;    &lt;date&gt;     &lt;fct&gt;       &lt;dbl&gt; &lt;fct&gt;    &lt;ord&gt; \n#&gt;  1 1854-04-01 질병          1.4 조치이전 4     \n#&gt;  2 1854-04-01 부상          0   조치이전 4     \n#&gt;  3 1854-04-01 기타          7   조치이전 4     \n#&gt;  4 1854-05-01 질병          6.2 조치이전 5     \n#&gt;  5 1854-05-01 부상          0   조치이전 5     \n#&gt;  6 1854-05-01 기타          4.6 조치이전 5     \n#&gt;  7 1854-06-01 질병          4.7 조치이전 6     \n#&gt;  8 1854-06-01 부상          0   조치이전 6     \n#&gt;  9 1854-06-01 기타          2.5 조치이전 6     \n#&gt; 10 1854-07-01 질병        150   조치이전 7     \n#&gt; # ℹ 62 more rows",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 과학 맛보기</span>"
    ]
  },
  {
    "objectID": "intro_whole_game.html#시각화",
    "href": "intro_whole_game.html#시각화",
    "title": "\n3  데이터 과학 맛보기\n",
    "section": "\n3.3 시각화",
    "text": "3.3 시각화\n‘ggplot2’ 패키지를 이용하여 크림전쟁 나이팅게일 활약상을 담은 데이터를 시각화한다. 나이팅게일 활약 전과 후로 데이터(death_viz)를 나눠 “크림전쟁 병사 사망원인”에 대한 극좌표계 시각화를 통해 이해하기 쉬운 설득력있는 시각화 결과물을 제시하고 있다. 추가적으로, ‘showtext’ 패키지로 구글 “Noto Serif KR” 글꼴을 선택적용하고, ‘hrbrthemes’ 라이브러리를 이용하여 뒷 배경 검정색을 사용하여 붉은색 질병으로 인한 사망자수 확연한 감소를 시각적으로 강조한다.\n\nlibrary(hrbrthemes) \nlibrary(showtext)\nshowtext.auto()\nfont_add_google(name = \"Noto Serif KR\", family = \"noto_serif\")\nnoto_font &lt;- \"noto_serif\"\n\ndeath_gg &lt;- death_viz %&gt;% \n  ggplot(aes(x = 해당월, y = 사망자수, fill = 사망원인)) +\n  geom_col(color = \"grey20\") + \n  theme_modern_rc(base_family = noto_font, subtitle_family = noto_font) + \n  scale_fill_manual(values = c(\"firebrick\", \"orange\", \"#365181\"), name = \"\") +\n  scale_y_sqrt() +\n  facet_wrap(~ 체제) + \n  coord_equal(ratio = 1) +  \n  coord_polar() +\n  labs(title = \"크림전쟁 병사 사망원인\", \n       subtitle = \"데이터 시각화와 커뮤니케이션\", \n       caption = \"데이터 출처: 크림전쟁 사망자\") + \n  theme(legend.position = \"top\", \n        text = element_text(family = noto_font, size = 18),\n        axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks = element_blank(),\n        plot.margin = unit(rep(0.7, 4), \"cm\"),\n        plot.title = element_text(color = \"white\", family = noto_font, size = 25),\n        plot.caption = element_text(color = \"grey70\", family = noto_font, size = 12),\n        plot.subtitle = element_text(color = \"grey70\", size = 13),\n        legend.text = element_text(color = \"white\", size = 15),\n        strip.text = element_text(color = \"white\", size = 25, face = \"bold\", family = noto_font, hjust = 0.5))\n\ndeath_gg\n\n\n\n\n\n\n\n\n3.3.1 선그래프\n나이팅게일은 간호 분야의 선구자로 잘 알려져 있지만, 통계학자로서 “콕스콤(CoxComb)” 또는 “장미 다이어그램”(Rose Diagram)으로 알려진 원그래프를 제시하였지만 현재는 시간의 흐름에 따라 병사 사망자수 변화를 조치 전후로 명확히 하는 방법으로 선그래프가 기본 기법으로 자리잡고 있다.\n\nextrafont::loadfonts()\n\ndeath_new_gg &lt;- death_viz |&gt; \n  ggplot(aes(x = Date, y = 사망자수, color = 사망원인)) +\n    geom_line() +\n    geom_point() +\n    geom_vline(xintercept = as.Date(\"1855-03-15\"), linetype= 2) +\n    theme_ipsum_pub(base_family = noto_font, subtitle_family = noto_font) +\n    labs(title = \"크림전쟁 병사 사망원인\", \n         subtitle = \"데이터 시각화와 커뮤니케이션\", \n         caption = \"데이터 출처: 크림전쟁 사망자\",\n         x = \"월일\") + \n    scale_y_continuous(labels = scales::comma, limits = c(0, 1150)) +\n    theme(legend.position = \"top\", \n          text = element_text(family = noto_font, size = 18),\n          axis.ticks = element_blank(),\n          plot.margin = unit(rep(0.7, 4), \"cm\"),\n          plot.title = element_text(color = \"black\", family = noto_font, size = 35),\n          plot.caption = element_text(color = \"grey10\", family = noto_font, size = 17),\n          plot.subtitle = element_text(color = \"grey5\", size = 13),\n          legend.text = element_text(color = \"black\", size = 15)) +\n    geom_segment(x = as.Date(\"1854-03-01\"), y = 1100,\n                 xend = as.Date(\"1855-03-01\"), yend = 1100,\n                 color = \"gray70\",\n                 arrow = arrow(length = unit(0.1, \"inches\"))) +\n    geom_segment(x = as.Date(\"1855-04-01\"), y = 1100,\n                 xend = as.Date(\"1856-03-01\"), yend = 1100,\n                 color = \"gray15\",\n                 arrow = arrow(length = unit(0.1, \"inches\"))) +\n    annotate(\"text\", x = as.Date(\"1854-09-01\"), y = 1140, label = \"조치이전\",\n             size = 8.5, color = \"gray30\", family = noto_font) +\n    annotate(\"text\", x = as.Date(\"1855-09-01\"), y = 1140, label = \"조치이후\",\n             size = 8.5, color = \"gray15\", family = noto_font)          \n\ndeath_new_gg\n\n\n\n\n\n\n\n\n3.3.2 막대그래프\n동일한 정보를 막대그래프를 통해 시각화를 할 수도 있다. 원그래프와 비교하여 보면 명확하게 사망자수를 직관적으로 비교할 수 있다는 점에서 큰 장점이 있다.\n\ndeath_viz |&gt; \n  ggplot() +\n    geom_col(aes(x = Date, y = 사망자수, fill = 사망원인), colour=\"white\") +\n    geom_vline(xintercept = as.Date(\"1855-03-15\"), linetype= 2) +\n    scale_fill_manual(values = c(\"firebrick\", \"orange\", \"#365181\")) + \n    # theme_ipsum_pub(base_family = noto_font, subtitle_family = noto_font) +\n    labs(title = \"크림전쟁 병사 사망원인\", \n         subtitle = \"데이터 시각화와 커뮤니케이션\", \n         caption = \"데이터 출처: 크림전쟁 사망자\",\n         x = \"월일\") + \n    scale_y_continuous(labels = scales::comma, limits = c(0, 1150)) +\n    theme(legend.position = \"top\", \n          text = element_text(family = noto_font, size = 18),\n          axis.ticks = element_blank(),\n          plot.margin = unit(rep(0.7, 4), \"cm\"),\n          plot.title = element_text(color = \"black\", family = noto_font, size = 35),\n          plot.caption = element_text(color = \"grey10\", family = noto_font, size = 17),\n          plot.subtitle = element_text(color = \"grey5\", size = 13),\n          legend.text = element_text(color = \"black\", size = 15)) +\n    geom_segment(x = as.Date(\"1854-03-01\"), y = 1100,\n                 xend = as.Date(\"1855-03-01\"), yend = 1100,\n                 color = \"gray70\",\n                 arrow = arrow(length = unit(0.1, \"inches\"))) +\n    geom_segment(x = as.Date(\"1855-04-01\"), y = 1100,\n                 xend = as.Date(\"1856-03-01\"), yend = 1100,\n                 color = \"gray15\",\n                 arrow = arrow(length = unit(0.1, \"inches\"))) +\n    annotate(\"text\", x = as.Date(\"1854-09-01\"), y = 1140, label = \"조치이전\",\n             size = 8.5, color = \"gray30\", family = noto_font) +\n    annotate(\"text\", x = as.Date(\"1855-09-01\"), y = 1140, label = \"조치이후\",\n             size = 8.5, color = \"gray15\", family = noto_font)",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 과학 맛보기</span>"
    ]
  },
  {
    "objectID": "intro_whole_game.html#표-문법",
    "href": "intro_whole_game.html#표-문법",
    "title": "\n3  데이터 과학 맛보기\n",
    "section": "\n3.4 표 문법",
    "text": "3.4 표 문법\n데이터 문법, 그래프 문법에 이어 최근 “표 문법”이 새롭게 자리를 잡아가고 있다. 표 문법에 맞춰 나이팅게일 크림전쟁 사망자수를 조치 이전과 조치 이후로 나눠 요약하면 확연한 차이를 파악할 수 있다.\ngt와 gtExtras 패키지를 활용하여 death_viz 데이터프레임을 사망 원인별 사망자 수를 “조치 이전”과 “조치 이후”로 구분하여 표를 두개 생성한다. 각 표은 날짜, 질병, 부상, 기타 범주로 사망자 수와 그 합계를 표시하며, 총 사망자수가 250명을 초과하는 행에 대한 강조 색상을 입히고 나서 두 표를 나란히 배치하여 조치 전후 효과를 시각적으로 비교한다.\n\nlibrary(gt)\nlibrary(gtExtras)\n\nbefore_tbl &lt;- death_viz |&gt; \n  filter(체제 == \"조치이전\")\n\nafter_tbl &lt;- death_viz |&gt; \n  filter(체제 == \"조치이후\")\n\nbefore_gt &lt;- before_tbl |&gt; \n  pivot_wider(names_from = 사망원인, values_from = 사망자수) |&gt; \n  select(날짜 = Date, 질병, 부상, 기타) |&gt; \n  mutate(합계 = 질병 + 부상 + 기타) |&gt; \n  gt() |&gt; \n    gt_theme_538() |&gt; \n    cols_align(\"center\") |&gt; \n    fmt_integer( columns = 질병:합계) |&gt; \n    tab_spanner(label = \"조치 이전\", columns = c(질병, 부상, 기타)) |&gt; \n    data_color(\n      columns = c(질병, 부상, 기타, 합계),\n      rows = 합계 &gt; 250,      \n      method = \"numeric\",\n      palette = \"ggsci::red_material\")\n\nafter_gt &lt;- after_tbl |&gt; \n  pivot_wider(names_from = 사망원인, values_from = 사망자수) |&gt; \n  select(날짜 = Date, 질병, 부상, 기타) |&gt; \n  mutate(합계 = 질병 + 부상 + 기타) |&gt; \n  gt() |&gt; \n    gt_theme_538() |&gt; \n    cols_align(\"center\") |&gt; \n    fmt_integer( columns = 질병:합계) |&gt; \n  tab_spanner(label = \"조치 이후\", columns = c(질병, 부상, 기타)) |&gt; \n  data_color(\n    columns = c(질병, 부상, 기타, 합계),\n    rows = 합계 &gt; 250,      \n    method = \"numeric\",\n    palette = \"ggsci::red_material\")\n\ngtExtras::gt_two_column_layout(list(before_gt, after_gt))\n\n\n\n\n\n\n\n\n\n날짜\n조치 이전\n합계\n\n\n질병\n부상\n기타\n\n\n\n\n1854-04-01\n1\n0\n7\n8\n\n\n1854-05-01\n6\n0\n5\n11\n\n\n1854-06-01\n5\n0\n2\n7\n\n\n1854-07-01\n150\n0\n10\n160\n\n\n1854-08-01\n328\n0\n12\n341\n\n\n1854-09-01\n312\n32\n28\n372\n\n\n1854-10-01\n197\n52\n50\n299\n\n\n1854-11-01\n341\n116\n43\n499\n\n\n1854-12-01\n632\n42\n48\n721\n\n\n1855-01-01\n1,023\n31\n120\n1,174\n\n\n1855-02-01\n823\n16\n140\n979\n\n\n1855-03-01\n480\n13\n69\n562\n\n\n\n\n\n\n\n\n\n\n\n날짜\n조치 이후\n합계\n\n\n질병\n부상\n기타\n\n\n\n\n1855-04-01\n178\n18\n21\n217\n\n\n1855-05-01\n172\n17\n12\n201\n\n\n1855-06-01\n248\n64\n10\n322\n\n\n1855-07-01\n108\n38\n9\n154\n\n\n1855-08-01\n130\n44\n7\n181\n\n\n1855-09-01\n48\n69\n5\n122\n\n\n1855-10-01\n33\n14\n5\n51\n\n\n1855-11-01\n56\n10\n10\n77\n\n\n1855-12-01\n25\n5\n8\n38\n\n\n1856-01-01\n11\n0\n13\n25\n\n\n1856-02-01\n7\n0\n5\n12\n\n\n1856-03-01\n4\n0\n9\n13",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 과학 맛보기</span>"
    ]
  },
  {
    "objectID": "intro_whole_game.html#커뮤니케이션",
    "href": "intro_whole_game.html#커뮤니케이션",
    "title": "\n3  데이터 과학 맛보기\n",
    "section": "\n3.5 커뮤니케이션",
    "text": "3.5 커뮤니케이션\n데이터를 기반으로 뭔가 유용한 것을 창출한 후에 이를 알리기 위해 커뮤니케이션 단계를 거치게 된다. 가장 흔히 사용하는 방식은 엑셀, 워드, 파워포인트와 같은 MS 오피스 제품을 활용하는 방식이다. 과거 SAS, SPSS, 미니탭 등 외산 통계 팩키지로 데이터를 분석하고 유용한 모형 등을 찾아낸 후에 이를 커뮤니케이션하기 위해 MS 오피스 제품을 통해 커뮤니케이션을 하기도 했다. 하지만, 각각은 별개의 시스템으로 분리되어 있어 일일이 사람손이 가는 번거러움이 많았다. 이를 해결하기 하는 방법은 하나의 도구 혹은 언어로 모든 작업을 처리하는 것이다. [^meghan]\n[^meghan] : Meghan Hall (June 15, 2021), “Extending R Markdown”, RStudio: R in Sports Analytics,\n우선 엑셀은 tidyverse 로 대체가 되고, 워드는 R 마크다운을 거쳐 쿼토(Quarto), 파워포인트도 R 마크다운(xaringan 등)에서 진화한 reveal.js 기반 쿼토 슬라이드가 빠르게 자리를 잡아가고 있다.\n\n\n오피스 기반 커뮤니케이션 현재 상태점검\n\n데이터 과학을 커뮤니케이션하는 방식은 다양한 방식이 존재하지만 직장상사 뿐만 아니라 집단지성을 넘어 AI를 적극 도입하여 데이터 분석 역량을 고도화하는데 동료 개발자 및 협업하시는 분들과 커뮤니케이션 뿐만 아니라 불특정 다수를 대상으로 한 인터넷에 공개와 공유를 통해 새로운 관계를 맺어가는 것도 그 중요성을 더해가고 있다.\n\n동료 개발자나 협업하시는 분: .qmd 파일\n직장상사\n\nPDF 파일: quarto, pandoc\n\n파워포인트 슬라이스덱: reveal.js 기반 quarto\n\n대쉬보드: flexdashboard\n\n\n\n일반 공개\n\n웹사이트: distill을 지나 quarto\n\n블로그: blogdown을 지나 quarto\n\n책: bookdown을 지나 quarto",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>데이터 과학 맛보기</span>"
    ]
  },
  {
    "objectID": "intro_penguins.html",
    "href": "intro_penguins.html",
    "title": "\n4  펭귄 데이터셋\n",
    "section": "",
    "text": "5 펭귄 데이터셋",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>펭귄 데이터셋</span>"
    ]
  },
  {
    "objectID": "intro_penguins.html#펭귄-데이터-출현",
    "href": "intro_penguins.html#펭귄-데이터-출현",
    "title": "\n4  펭귄 데이터셋\n",
    "section": "\n5.1 펭귄 데이터 출현",
    "text": "5.1 펭귄 데이터 출현\n미국에서 “George Floyd”가 경찰에 의해 살해되면서 촉발된 “Black Lives Matter” 운동은 아프리카계 미국인을 향한 폭력과 제도적 인종주의에 반대하는 사회운동이다. 한국에서도 소수 정당인 정의당에서 여당 의원 176명 중 누가?…차별금지법 발의할 ’의인’을 구합니다로 기사로 낼 정도로 적극적으로 나서고 있다.\n데이터 과학에서 최근 R.A. Fisher의 과거 저술한 “The genetical theory of natural selection” (fisher1958genetical?) 우생학(Eugenics) 대한 관점이 논란이 되면서 R 데이터 과학의 첫 데이터셋으로 붓꽃 iris 데이터를 다른 데이터, 즉 펭귄 데이터로 대체하는 움직임이 활발히 전개되고 있다. palmerpenguins (penguin2020?) 데이터셋이 대안으로 많은 호응을 얻고 있다. (Levy2019?)",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>펭귄 데이터셋</span>"
    ]
  },
  {
    "objectID": "intro_penguins.html#penguins-study",
    "href": "intro_penguins.html#penguins-study",
    "title": "\n4  펭귄 데이터셋\n",
    "section": "\n5.2 펭귄 공부",
    "text": "5.2 펭귄 공부\n팔머(Palmer) 펭귄은 3종이 있으며 자세한 내용은 다음 나무위키를 참조한다. 1\n\n\n젠투 펭귄(Gentoo Penguin): 머리에 모자처럼 둘러져 있는 하얀 털 때문에 알아보기가 쉽다. 암컷이 회색이 뒤에, 흰색이 앞에 있다. 펭귄들 중에 가장 빠른 시속 36km의 수영 실력을 자랑하며, 짝짓기 할 준비가 된 펭귄은 75-90cm까지도 자란다.\n\n아델리 펭귄(Adelie Penguin): 프랑스 탐험가인 뒤몽 뒤르빌(Dumont D’Urville) 부인의 이름을 따서 ’아델리’라 불리게 되었다. 각진 머리와 작은 부리 때문에 알아보기 쉽고, 다른 펭귄들과 마찬가지로 암수가 비슷하게 생겼지만 암컷이 조금 더 작다.\n\n턱끈 펭귄(Chinstrap Penguin): 언뜻 보면 아델리 펭귄과 매우 비슷하지만, 몸집이 조금 더 작고, 목에서 머리 쪽으로 이어지는 검은 털이 눈에 띈다. 어린 고삐 펭귄들은 회갈색 빛을 띄는 털을 가지고 있으며, 목 아래 부분은 더 하얗다. 무리를 지어 살아가며 일부일처제를 지키기 때문에 짝짓기 이후에도 부부로써 오랫동안 함께 살아간다.\n\n\n\n팔머 펭귄 3종 세트\n\n다음으로 iris 데이터와 마찬가지로 펭귄 3종을 구분하기 위한 변수로 조류의 부리에 있는 중앙 세로선의 융기를 지칭하는 능선(culmen) 길이(culmen length)와 깊이(culmen depth)를 이해하면 된다.\n\n\n팔머 펭귄 능선 변수",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>펭귄 데이터셋</span>"
    ]
  },
  {
    "objectID": "intro_penguins.html#penguin-home",
    "href": "intro_penguins.html#penguin-home",
    "title": "\n4  펭귄 데이터셋\n",
    "section": "\n5.3 펭귄 서식지",
    "text": "5.3 펭귄 서식지\nleaflet 팩키지로 펭귄 서식지를 남극에서 특정한다. geocoding을 해야 하는데 구글에서 위치 정보를 구글링하면 https://latitude.to/에서 직접 위경도를 반환하여 준다. 이 정보를 근거로 하여 펭귄 서식지를 시각화한다.\n\n\n\n\n\n\n\n\n파머 연구소와 펭귄 서식지\n\n\n\n\n\n펭귄 3종\n\n\n\n\n\n\n\n아델리, 젠투, 턱끈 펭귄이 함께한 사진\n\n\n\n\n\n토르거센 섬에서 새끼를 키우는 아델리 펭귄\n\n\n\n\n\n비스코 지점 젠투 펭귄 서식지\n\n\n\n\n\n펭귄과 함께 현장에서 일하는 크리스틴 고먼 박사\n\n\n\n\n\n파머 펭귄 데이터셋\n\n\n\n\nlibrary(tidyverse)\nlibrary(leaflet)\nlibrary(palmerpenguins)\n# library(tidygeocoder)\n\npenguins %&gt;% \n  count(island)\n#&gt; # A tibble: 3 × 2\n#&gt;   island        n\n#&gt;   &lt;fct&gt;     &lt;int&gt;\n#&gt; 1 Biscoe      168\n#&gt; 2 Dream       124\n#&gt; 3 Torgersen    52\n\nisland_df &lt;- tribble(~\"address\", ~\"lat\", ~\"lng\",\n                     \"Torgersen Island antarctica\", -64.772819, -64.074325,\n                     \"Dream Island antarctica\", -64.725558, -64.225562,\n                     \"Biscoe Island antarctica\", -64.811565, -63.777947,\n                     \"Palmer Station\", -64.774312, -64.054213)\n\nisland_df %&gt;% \n  leaflet() %&gt;% \n  addProviderTiles(providers$OpenStreetMap) %&gt;% \n  addMarkers(lng=~lng, lat=~lat, \n                   popup = ~ as.character(paste0(\"&lt;strong&gt;\", paste0(\"명칭:\",`address`), \"&lt;/strong&gt;&lt;br&gt;\",\n                                                 \"-----------------------------------------------------------&lt;br&gt;\",\n                                                 \"&middot; latitude: \", `lat`, \"&lt;br&gt;\",\n                                                 \"&middot; longitude: \", `lng`, \"&lt;br&gt;\"\n                   )))",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>펭귄 데이터셋</span>"
    ]
  },
  {
    "objectID": "intro_penguins.html#데이터-설치",
    "href": "intro_penguins.html#데이터-설치",
    "title": "\n4  펭귄 데이터셋\n",
    "section": "\n5.4 데이터 설치",
    "text": "5.4 데이터 설치\nremotes 팩키지 install_github() 함수로 펭귄 데이터를 설치한다.\n\n# install.packages(\"remotes\")\nremotes::install_github(\"allisonhorst/palmerpenguins\")\n\ntidyverse 팩키지 glimpse() 함수로 펭귄 데이터를 일별한다.\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\nglimpse(penguins)\n#&gt; Rows: 344\n#&gt; Columns: 8\n#&gt; $ species           &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n#&gt; $ island            &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n#&gt; $ bill_length_mm    &lt;dbl&gt; 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n#&gt; $ bill_depth_mm     &lt;dbl&gt; 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n#&gt; $ flipper_length_mm &lt;int&gt; 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n#&gt; $ body_mass_g       &lt;int&gt; 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n#&gt; $ sex               &lt;fct&gt; male, female, female, NA, female, male, female, male…\n#&gt; $ year              &lt;int&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>펭귄 데이터셋</span>"
    ]
  },
  {
    "objectID": "intro_penguins.html#penguin-EDA-skimr",
    "href": "intro_penguins.html#penguin-EDA-skimr",
    "title": "\n4  펭귄 데이터셋\n",
    "section": "\n5.5 자료구조 일별",
    "text": "5.5 자료구조 일별\nskimr 팩키지를 사용해서 penguins 데이터프레임 자료구조를 일별한다. 이를 통해서 344개 펭귄 관측값이 있으며, 7개 칼럼으로 구성된 것을 확인할 수 있다. 또한, 범주형 변수가 3개, 숫자형 변수가 4개로 구성되어 있다. 그외 더 자세한 사항은 범주형, 숫자형 변수에 대한 요약 통계량을 참조한다.\n\nskimr::skim(penguins)\n\n\nData summary\n\n\nName\npenguins\n\n\nNumber of rows\n344\n\n\nNumber of columns\n8\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\nspecies\n0\n1.00\nFALSE\n3\nAde: 152, Gen: 124, Chi: 68\n\n\nisland\n0\n1.00\nFALSE\n3\nBis: 168, Dre: 124, Tor: 52\n\n\nsex\n11\n0.97\nFALSE\n2\nmal: 168, fem: 165\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\nbill_length_mm\n2\n0.99\n43.92\n5.46\n32.1\n39.23\n44.45\n48.5\n59.6\n▃▇▇▆▁\n\n\nbill_depth_mm\n2\n0.99\n17.15\n1.97\n13.1\n15.60\n17.30\n18.7\n21.5\n▅▅▇▇▂\n\n\nflipper_length_mm\n2\n0.99\n200.92\n14.06\n172.0\n190.00\n197.00\n213.0\n231.0\n▂▇▃▅▂\n\n\nbody_mass_g\n2\n0.99\n4201.75\n801.95\n2700.0\n3550.00\n4050.00\n4750.0\n6300.0\n▃▇▆▃▂\n\n\nyear\n0\n1.00\n2008.03\n0.82\n2007.0\n2007.00\n2008.00\n2009.0\n2009.0\n▇▁▇▁▇\n\n\n\n\n\n데이터가 크지 않아 DT 팩키지를 통해 데이터 전반적인 내용을 살펴볼 수 있다.\n\npenguins %&gt;% \n  reactable::reactable()",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>펭귄 데이터셋</span>"
    ]
  },
  {
    "objectID": "intro_penguins.html#penguin-EDA",
    "href": "intro_penguins.html#penguin-EDA",
    "title": "\n4  펭귄 데이터셋\n",
    "section": "\n5.6 탐색적 데이터 분석",
    "text": "5.6 탐색적 데이터 분석\npalmerpenguins 데이터셋 소개에 포함되어 있는 미국 팔머 연구소 (palmer station) 펭귄 물갈퀴(flipper) 길이와 체질량(body mass) 산점도를 그려보자.\n\nlibrary(tidyverse)\nlibrary(extrafont)\nloadfonts()\n\nmass_flipper &lt;- ggplot(data = penguins, \n                       aes(x = flipper_length_mm,\n                           y = body_mass_g)) +\n  geom_point(aes(color = species, \n                 shape = species),\n             size = 3,\n             alpha = 0.8) +\n  theme_minimal(base_family = \"NanumGothic\") +\n  scale_color_manual(values = c(\"darkorange\",\"purple\",\"cyan4\")) +\n  labs(title = \"펭귄 크기\",\n       subtitle = \"남극 펭귄 3종 물갈퀴 길이와 체질량 관계\",\n       x = \"물갈퀴 길이 (mm)\",\n       y = \"체질량 (g)\",\n       color = \"펭귄 3종\",\n       shape = \"펭귄 3종\") +\n  theme(legend.position = c(0.2, 0.7),\n        legend.background = element_rect(fill = \"white\", color = NA),\n        plot.title.position = \"plot\",\n        plot.caption = element_text(hjust = 0, face= \"italic\"),\n        plot.caption.position = \"plot\")\n\nmass_flipper",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>펭귄 데이터셋</span>"
    ]
  },
  {
    "objectID": "intro_penguins.html#펭귄-데이터-저장",
    "href": "intro_penguins.html#펭귄-데이터-저장",
    "title": "\n4  펭귄 데이터셋\n",
    "section": "\n5.7 펭귄 데이터 저장",
    "text": "5.7 펭귄 데이터 저장\n\n5.7.1 .csv 파일\n\nlibrary(palmerpenguins)\n\npenguins |&gt; \n  drop_na() |&gt; \n  write_csv(\"data/penguins.csv\")\n\n\n5.7.2 .xlsx 엑셀 파일\n\nlibrary(writexl)\n\npenguins |&gt; \n  drop_na() |&gt; \n  write_xlsx(\"data/penguins.xlsx\")\n\n\n5.7.3 .sqlite 데이터베이스\n\nlibrary(DBI)\nlibrary(RSQLite)\n\ncon &lt;- dbConnect(RSQLite::SQLite(), dbname = \"data/penguins.sqlite\")\n\n# 데이터프레임을 SQLite 테이블로 저장합니다. 'my_table'이라는 이름으로 저장됩니다.\n# 데이터베이스에 같은 이름의 테이블이 이미 존재한다면, append, overwrite 또는 fail 중 하나를 선택할 수 있습니다.\ndbWriteTable(con, \"penguin\", penguins |&gt; drop_na() , overwrite = TRUE)\n\n# 연결을 닫습니다.\ndbDisconnect(con)\n\n\n5.7.4 pins\n\n\nlibrary(pins)\n\nboard &lt;- board_folder(\"C:/Users/statkclee/OneDrive/pins\") \n\nmetadata &lt;- list(owner       = \"한국 R 사용자회\",\n                 deptartment = \"R&D\",\n                 URL         = \"https://r2bit.com\")\n\nboard  |&gt; pin_write(penguins |&gt; drop_na(), \n                    name        = \"penguins\",\n                    title       = \"펭귄 데이터셋\",\n                    description = \"남극 파머 연구소 서식 펭귄 데이터셋\",\n                    metadata    = metadata)\n\n\n5.7.5 구글시트\n\nlibrary(googlesheets4)\nlibrary(googledrive)\n\ngoogledrive::drive_auth()\n\ngs4_create(\n  name = \"penguins\",\n  sheets = list(\"penguins\" = penguins |&gt; drop_na())\n)\n\n#&gt; ✔ Creating new Sheet: penguins.\n#&gt; Waiting for authentication in browser...\n#&gt; Press Esc/Ctrl + C to abort\n#&gt; Authentication complete.",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>펭귄 데이터셋</span>"
    ]
  },
  {
    "objectID": "intro_penguins.html#footnotes",
    "href": "intro_penguins.html#footnotes",
    "title": "\n4  펭귄 데이터셋\n",
    "section": "",
    "text": "신발끈 여행사, 관광안내자료↩︎",
    "crumbs": [
      "**1부** 들어가며",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>펭귄 데이터셋</span>"
    ]
  },
  {
    "objectID": "functions.html",
    "href": "functions.html",
    "title": "\n16  함수\n",
    "section": "",
    "text": "16.1 함수 기본 지식\n함수는 입력값(x)를 넣어 어떤 작업(f)을 수행한 결과를 반환(y) 과정으로 이해할 수 있는데, 인자로 다양한 값을 함수에 넣을 수 있고, 물론 함수가 뭔가 유용한 작업을 수행하기 위한 전제조건을 만족시키는지 확인하는 과정을 assert 개념을 넣어 확인하고 기술된 작업을 수행한 후에 출력값을 변환시키게 된다.",
    "crumbs": [
      "**5부** 프로그래밍",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>함수</span>"
    ]
  },
  {
    "objectID": "functions.html#all-about-function",
    "href": "functions.html#all-about-function",
    "title": "\n16  함수\n",
    "section": "",
    "text": "데이터 과학 함수 개념",
    "crumbs": [
      "**5부** 프로그래밍",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>함수</span>"
    ]
  },
  {
    "objectID": "functions.html#how-to-use-function",
    "href": "functions.html#how-to-use-function",
    "title": "\n16  함수\n",
    "section": "\n16.2 함수 사용법",
    "text": "16.2 함수 사용법\n본격적으로 함수를 작성하기 전에 먼저, 함수를 사용하는 방법을 익히는 것이 필요하다. 함수는 함수명, 인자(argument), 함수 몸통(body), 반환값(return value)으로 구성된다.\n데이터 과학 대표 언어 R과 파이썬으로 4칙연산을 구현하는 함수를 작성하여 자세히 살펴보자.\n\n16.2.1 R 함수\n\n함수명: 함수명을 먼저 적고 &lt;-, function(), {, } 순으로 R이 함수임을 알 수 있도록 전개한다.\n함수 인자: 함수에 넣을 인자를 정의하여 넣어 둔다.\n함수 몸통(body): 앞서 사칙연산처럼 함수가 수행해야 되는 작업을 기술한다.\n반환값(return): return 예약어로 함수작업결과 반환되는 값을 명시할 수도 있고, 그냥 놔두면 마지막 객체가 자동으로 반환된다.\n\n\nbasic_operation &lt;- function(first, second) {\n  sum_number &lt;- first + second\n  minus_number &lt;- first - second\n  multiply_number &lt;- first * second\n  divide_number &lt;- first / second\n  \n  result &lt;- list(sum_number, minus_number, multiply_number, divide_number)\n  \n  return(result)\n}\n\nbasic_operation(7, 3)\n#&gt; [[1]]\n#&gt; [1] 10\n#&gt; \n#&gt; [[2]]\n#&gt; [1] 4\n#&gt; \n#&gt; [[3]]\n#&gt; [1] 21\n#&gt; \n#&gt; [[4]]\n#&gt; [1] 2.333333\n\n\n16.2.2 파이썬 함수\n\n함수 머리(header): def로 함수임을 선언하고, 함수명과 함수인자를 기술, 마지막을 :으로 마무리.\n함수 설명: docstring으로 ““” … ““” 으로 함수에 대한 도움말을 기술한다. 함수가 하는 역할, 매개변수, 반환되는 값, 예제 등을 넣어 개발자가 봤을 때 피로도가 없도록 작성한다.\n함수 몸통(body): 앞서 사칙연산처럼 함수가 수행해야 되는 작업을 기술한다.\n반환값(return): return 예약어로 함수작업결과 반환되는 값을 지정한다.\n\n\ndef basic_operation(first, second):\n    \"\"\"\n    숫자 두개를 받아 사칙연산을 수행하는 함수.\n    \n    예제\n        basic_operation(10, 20)\n    매개변수(args)\n        first(int): 정수형 숫자\n        second(int): 정수형 숫자\n    반환값(return)\n        리스트: +-*/ 사칙연산 결과\n    \"\"\"\n    sum_number = first + second\n    minus_number = first - second\n    multiply_number = first * second\n    divide_number = first / second\n    \n    result = [sum_number, minus_number, multiply_number, divide_number]\n    \n    return result\n    \nbasic_operation(7, 3)    \n#&gt; [10, 4, 21, 2.3333333333333335]\n\n다른 사람이 작성한 함수를 사용한다는 것은 좀더 엄밀한 의미로 함수를 호출(call)한다고 한다. 함수를 호출해서 다른 사람이 작성한 함수를 사용하기 위해서 먼저 함수명을 알아야 하고, 그 다음으로 함수에서 사용되는 인자(arugment)를 파악해서 올바르게 전달해야 원하는 결과를 얻을 수 있다.\n표준편차(sd)를 계산하는 sd 함수의 경우 전달되는 인자는 두개 x, na.rm = FALSE인데 이를 확인할 수 있는 명령어가 args() 함수다.\n\nargs(sd)\n#&gt; function (x, na.rm = FALSE) \n#&gt; NULL\n\nx는 ? sd 명령어를 통해서 숫자 벡터를 전달해 주어야만 표준편차를 계산할 수 있다. 예를 들어, 데이터프레임(penguins)의 변수 하나(bill_length_mm)를 지정하여 전달하고 na.rm = TRUE도 명세하여 인자로 전달한다. 인자값이 기본디폴트 값으로 설정된 경우 타이핑을 줄일 수 있고, 결측값이 포함된 경우에 따라서 다른 인자를 넣어 전달하는 방식으로 함수를 사용한다.\n\nlibrary(palmerpenguins)\n\nsd(penguins$bill_length_mm, na.rm = TRUE)\n#&gt; [1] 5.459584",
    "crumbs": [
      "**5부** 프로그래밍",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>함수</span>"
    ]
  },
  {
    "objectID": "functions.html#convert-scripts-to-function",
    "href": "functions.html#convert-scripts-to-function",
    "title": "\n16  함수\n",
    "section": "\n16.3 스크립트 → 함수",
    "text": "16.3 스크립트 → 함수\n함수를 작성하는 경우는 먼저 데이터를 가져와서 정제하고 EDA과정을 거치며 모형과 시각화 산출물을 제작하는 과정을 거친다. 그리고 나서 이런 작업이 몇번 반복하게 되면 함수작성을 고려하게 된다. 즉, 스크립트에서 함수로 변환하는 과정을 설명하면 다음과 같다.\n\nR 함수 템플릿을 제작한다.\n\n함수명 &lt;- function() { }\n\n\n스크립트를 함수 몸통에 복사하여 붙인다.\n반복작업되는 인자를 찾아내 이를 인자로 넣어둔다.\n인자값과 연동되는 부분을 찾아 맞춰준다.\n함수명을 적절한 동사를 갖춘 이름으로 작명한다.\n\nreturn이 불필요하기 때문에 R 언어 특성을 반영하여 필요한 경우 제거한다.\n\n\n16.3.1 주사위\n먼저 주사위를 모사하여 보자. 즉, 주사위를 물리적으로 만드는 대신 주사위를 던진 것과 동일한 효과가 나타나도록 이를 구현해 본다.\n\n주사위 던지는 스크립트\n\n먼저 주사위 눈을 1,2,3,4,5,6 숫자 벡터로 정의하고 나서 sample() 함수로 size=1을 지정한다. 즉, 주사위 눈 6개중 임의로 하나를 선택한다.\n\ndice &lt;- c(1,2,3,4,5,6)\n\nsample(dice, size=1)\n#&gt; [1] 3\n\n\n함수 템플릿\n\n“함수명 &lt;- function() { }”으로 구성되는 함수 템플릿을 작성한다.\n\ndraw_dice &lt;- function() {\n  \n}\n\n\n함수 몸통으로 복사하여 붙여넣기\n\n함수 몸통내부에 dice &lt;- c(1,2,3,4,5,6)을 함수를 매번 호출할 때마다 실행시킬 필요는 없기 때문에 외부로 빼내고 실제 주사위 던지는 과정을 모사하는 코드만 복사하여 붙여넣는다.\n\ndice &lt;- c(1, 2, 3, 4, 5, 6)\n\ndraw_dice &lt;- function() {\n  sample(dice, size=1)\n}\n\ndraw_dice()\n#&gt; [1] 5\n\n\n함수명, 함수 인자 등 마무리\n\n함수명을 draw_dice 말고 다른 더 기억하기 좋고 짧고 간결한 형태로 필요한 경우 변경시키고, 인자도 없는 것에서 횟수를 지정할 수 있도록 변경시키고, 필요한 경우 return 함수를 지정하여 반환값을 명시적으로 적어 둔다.\n\ndraw_dice &lt;- function(num_try) {\n  face &lt;- sample(dice, size=num_try)\n  return(face) # 불필요함.\n}\n\ndraw_dice(3)\n#&gt; [1] 4 1 2",
    "crumbs": [
      "**5부** 프로그래밍",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>함수</span>"
    ]
  },
  {
    "objectID": "functions.html#why-write-function",
    "href": "functions.html#why-write-function",
    "title": "\n16  함수\n",
    "section": "\n16.4 왜 함수가 필요한가?",
    "text": "16.4 왜 함수가 필요한가?\n왜 함수가 필요한지를 데이터를 분석할 때 자주 나오는 변수 정규화 사례를 바탕으로 살펴보자. 데이터프레임에 담긴 변수의 측도가 상이하여 변수를 상대적으로 비교하기 위해 측도를 재조정하여 표준화할 필요가 있다. 변수에서 평균을 빼고 표준편차로 나누는 정규화도 있지만, 최대값에서 최소값을 빼서 분모에 두고 분자에 최소값을 빼서 나누면 모든 변수가 0–1 사이 값으로 척도가 조정된다.\n\\[ f(x)_{\\text{척도조정}} = \\frac{x-min(x)}{max(x)-min(x)} \\]\n\ndf &lt;- data.frame(a=c(1,2,3,4,5),\n                         b=c(10,20,30,40,50),\n                         c=c(7,8,6,1,3),\n                         d=c(5,4,6,5,2))\ndf$a &lt;- (df$a - min(df$a, na.rm = TRUE)) /\n        (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))\ndf$b &lt;- (df$b - min(df$b, na.rm = TRUE)) /\n        (max(df$a, na.rm = TRUE) - min(df$b, na.rm = TRUE))\ndf$c &lt;- (df$c - min(df$c, na.rm = TRUE)) /\n        (max(df$c, na.rm = TRUE) - min(df$c, na.rm = TRUE))\ndf$d &lt;- (df$d - min(df$d, na.rm = TRUE)) /\n        (max(df$d, na.rm = TRUE) - min(df$d, na.rm = TRUE))\ndf        \n#&gt;      a         b         c    d\n#&gt; 1 0.00  0.000000 0.8571429 0.75\n#&gt; 2 0.25 -1.111111 1.0000000 0.50\n#&gt; 3 0.50 -2.222222 0.7142857 1.00\n#&gt; 4 0.75 -3.333333 0.0000000 0.75\n#&gt; 5 1.00 -4.444444 0.2857143 0.00\n\n상기 R 코드는 측도를 모두 맞춰서 변수 4개(a, b, c, d)를 비교하거나 향후 분석을 위한 것이다. 하지만, 읽어야 하는 코드중복이 심하고 길어 코드를 작성한 개발자의 의도 가 본의 아니게 숨겨져 있다. 작성한 R 코드에 실수한 것이 있는 경우, 다음 프로그램 실행에서 버그(특히, 구문론이 아닌 의미론적 버그)가 숨겨지게 된다. 상기 코드가 작성되는 과정을 살펴보면 본의 아니게 의도가 숨겨진다는 의미가 어떤 것인지 명확해진다.\n\n\ndf$a &lt;- (df$a - min(df$a, na.rm = TRUE)) / (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE)) 코드를 작성한 후, 정상적으로 돌아가는지 확인한다.\n1번 코드가 잘 동작하게 되면 다음 복사하여 붙여넣기 신공을 사용하여 다른 칼럼 작업을 확장해 나간다. df$b, df$c, df$d를 생성하게 된다.\n즉, 복사해서 붙여넣은 것을 변수명을 편집해서 df$b, df$c, df$d 변수를 순차적으로 생성해 낸다.\n\n\n\n\n\n\n\n해들리 위캠 어록\n\n\n\n\n중복은 의도를 숨기게 되고, 복사하여 붙여넣기 두번하면 함수를 작성할 시점이 되었다. (Duplication hides the intent. If you have copied-and-pasted twice, it is time to write a function.)",
    "crumbs": [
      "**5부** 프로그래밍",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>함수</span>"
    ]
  },
  {
    "objectID": "functions.html#funciton-component",
    "href": "functions.html#funciton-component",
    "title": "\n16  함수\n",
    "section": "\n16.5 함수 구성요소",
    "text": "16.5 함수 구성요소\n\n16.5.1 인자(argument)\n함수 구성요소 중 중요한 요소로 인자(argument)를 꼽을 수 있다. 인자는 크게 두가지로 나뉜다.\n\n데이터 인자(data argumnets): 대다수 함수는 기본적으로 데이터에 대한 연산을 가정하고 있다. 따라서 데이터를 함수 인자로 지정하여 이를 함수몸통에서 처리하고 결과를 반환시키는 것은 당연한 귀결이다.\n동작방식 지정 인자(detail arguments): 함수가 동작하는 방식에 대해서 세부적으로 동작하는 방식에 대해서 지정할 필요가 있는데 이때 필요한 것이 동작방식 지정 인자가 된다.\n\n예를 들어 t.test() 함수를 살펴보면 x가 데이터 인자가 되며, 기타 alternative = c(\"two.sided\", \"less\", \"greater\"), mu = 0, paired = FALSE, var.equal = FALSE, conf.level = 0.95, ...은 함수가 구체적으로 어떻게 동작하는지 명세한 인자값이다.\n\n? t.test\n\n## Default S3 method:\nt.test(x, y = NULL,\n       alternative = c(\"two.sided\", \"less\", \"greater\"),\n       mu = 0, paired = FALSE, var.equal = FALSE,\n       conf.level = 0.95, ...)\n\n\n16.5.2 인자값 확인 - assert\n\n인자값이 제대로 입력되어야 함수몸통에서 기술한 연산작업이 제대로 수행될 수 있다. 이를 위해서 testthat, assertive, assertr, assertthat 등 수많은 팩키지가 존재한다. stopifnot(), stop() 등 Base R 함수를 사용해도 문제는 없다.\n다음과 같이 입력값에 NA가 포함된 경우 벡터의 합계를 구하는 함수가 동작하지 않거나 아무 의미없는 값을 반환시키곤 한다. 그리고 앞서 인자값을 잘 제어하지 않게 되면 귀중한 컴퓨팅 자원을 낭비하기도 한다. 이를 방기하기 위해서 stopifnot()함수로 함수 몸통을 수호하는 보호자처럼 앞서 인자값의 적절성에 대해서 검정을 먼저 수행한다. 그리고 나서 사전 유효성 검사를 통과한 인자값에 대해서만 함수 몸통에 기술된 연산작업을 수행하고 결과값을 반환시킨다.\n\nlibrary(testthat)\n\nnum_vector &lt;- c(1,2,3,4, 5)\nna_vector &lt;- c(1,2,3,NA, 5)\n\nsum_numbers &lt;- function(vec) {\n  \n  stopifnot(!any(is.na(vec)))\n  \n  total &lt;- 0\n\n  for(i in 1:length(vec)) {\n    total &lt;- total + vec[i]\n  }\n  total\n}\n\nsum_numbers(num_vector)\n#&gt; [1] 15\nsum_numbers(na_vector)\n#&gt; Error in sum_numbers(na_vector): !any(is.na(vec)) is not TRUE\n\n상기 코드의 문제점은 stopifnot() 함수가 잘못된 입력값에 대해서 문제가 무엇이고, 어떤 행동을 취해야 하는지 친절하지 않다는데 있다. 이를 assertive 팩키지를 활용해서 극복하는 방안을 살펴보자. asserive 팩키지를 설치하면 R 함수 작성에 걸림돌이 될 수 있는 거의 모든 사전 점검작업을 수행할 수 있다는 것이 매력적이다. install.packages(\"assertive\")를 실행하게 되면 함께 설치되는 팩키지는 다음과 같다.\n‘assertive.base’, ‘assertive.properties’, ‘assertive.types’, ‘assertive.numbers’, ‘assertive.strings’, ‘assertive.datetimes’, ‘assertive.files’, ‘assertive.sets’, ‘assertive.matrices’, ‘assertive.models’, ‘assertive.data’, ‘assertive.data.uk’, ‘assertive.data.us’, ‘assertive.reflection’, ‘assertive.code’\n\nlibrary(assertive)\n\nsum_numbers_assertive &lt;- function(vec) {\n  \n  assert_is_numeric(vec)\n  \n  if(assert_any_are_na(vec)) {\n      stop(\"벡터 x는 NA 값이 있어요. 그래서 총합을 구하는게 의미가 없네요\")\n  }\n  \n  total &lt;- 0\n\n  for(i in 1:length(vec)) {\n    total &lt;- total + vec[i]\n  }\n  total\n}\n\n# sum_numbers_assertive(num_vector)\nsum_numbers_assertive(na_vector)\n#&gt; Error in if (assert_any_are_na(vec)) {: the condition has length &gt; 1\n\n\n16.5.3 반환값 확인\nR은 파이썬과 달리 return()이 꼭 필요하지는 않다. 왜냐하면 마지막 객체가 자동으로 함수 반환값으로 정의되기 때문이다. 함수 반환값 관련하여 몇가지 사항을 알아두면 도움이 많이 된다.\n먼저 함수에서 반환되는 값이 하나가 아닌 경우 이를 담아내는 방법을 살펴보자. list()로 감싸 이를 반환하는 경우가 많이 사용되었지만, 최근 zeallot 팩키지가 도입되어 함수 출력값을 받아내는데 간결하고 깔끔하게 작업할 수 있게 되었다. zeallot vignette에 다양한 사례가 나와 있다.\n예를 들어 단변량 회귀모형의 경우 lm() 함수로 회귀식을 적합시킨다. 그리고 나서 coef() 함수로 절편과 회귀계수를 추출할 때 %&lt;-% 연산자를 사용하게 되면 해당값을 벡터객체에 할당시킬 수 있다.\n\nlibrary(tidyverse)\nlibrary(zeallot)\n\nc(inter, slope) %&lt;-% coef(lm(mpg ~ cyl, data = mtcars))\n\ncat(\"절편: \", inter, \"\\n기울기: \", slope)\n#&gt; 절편:  37.88458 \n#&gt; 기울기:  -2.87579\n\niris 데이터셋을 훈련/시험 데이터셋으로 쪼갠다. 이를 위해서 일양균등분포에서 난수를 생성시켜 8:2 비율로 훈련/시험 데이터를 나눈다. 그리고 나서, %&lt;-% 연산자로 훈련/시험 데이터로 나누어 할당하는 것도 가능하다. 각 붓꽃마다 0~1 사이 난수를 생성하여 할당한다. 그리고 난수값이 0.2 이상이면 훈련, 그렇지 않으면 시험 데이터로 구분한다.\n\n\niris_df &lt;- iris %&gt;% \n  mutate(runif = runif(n())) %&gt;% \n  mutate(train_test = ifelse(runif &gt; 0.2, \"train\", \"test\")) \n\nc(test, train) %&lt;-%  split(iris_df, iris_df$train_test)\n\ncat(\"총 관측점: \", nrow(iris), \"\\n훈련: \", nrow(train), \"\\n시험: \", nrow(test))\n#&gt; 총 관측점:  150 \n#&gt; 훈련:  120 \n#&gt; 시험:  30\n\n혹은, 회귀분석 결과를 list() 함수로 결합시켜 리스트로 반환시킨다. 이런 경우 결과값이 하나가 아니더라도 추후 리스트 객체를 풀어 활용하는 것이 가능하다.\n\nget_lm_statistics &lt;- function(df) {\n  mtcars_lm &lt;- lm(mpg ~ cyl, data=df)\n  \n  intercept &lt;- coef(mtcars_lm)[1]\n  beta      &lt;- coef(mtcars_lm)[2]\n  \n  lm_stats &lt;- list(intercept = intercept, \n                   beta = beta)\n  \n  return(lm_stats)\n}\n\nmtcars_list &lt;- get_lm_statistics(mtcars)\n\nmtcars_list\n#&gt; $intercept\n#&gt; (Intercept) \n#&gt;    37.88458 \n#&gt; \n#&gt; $beta\n#&gt;      cyl \n#&gt; -2.87579",
    "crumbs": [
      "**5부** 프로그래밍",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>함수</span>"
    ]
  },
  {
    "objectID": "functions.html#time-to-write-function",
    "href": "functions.html#time-to-write-function",
    "title": "\n16  함수\n",
    "section": "\n16.6 함수를 작성하는 시점",
    "text": "16.6 함수를 작성하는 시점\n복사해서 붙여넣는 것을 두번 하게 되면, 함수를 작성할 시점이다. 중복을 제거하는 한 방법이 함수를 작성하는 것이고, 함수를 작성하게 되면 의도가 명확해진다. 함수명을 rescale로 붙이고 이를 실행하게 되면, 의도가 명확하게 드러나게 되고, 복사해서 붙여넣게 되면서 생겨나는 중복과 반복에 의한 실수를 줄일 수 있게 되고, 향후 코드를 갱신할 때도 도움이 된다.\n\nrescale &lt;- function(x){\n  rng &lt;- range(x, na.rm = TRUE)\n  (x - rng[1]) / (rng[2] - rng[1])\n}\n\ndf$a &lt;- rescale(df$a)\ndf$b &lt;- rescale(df$b)\ndf$c &lt;- rescale(df$c)\ndf$d &lt;- rescale(df$d)\n\nrescale() 함수를 사용해서 복사하여 붙여넣는 중복을 크게 줄였으나, 여전히 함수명을 반복해서 복사하여 붙여넣기를 통해 코드를 작성했다. 함수형 프로그래밍을 사용하는 것으로 함수명을 반복적으로 사용하는 것조차도 피할 수 있다.\n\nlibrary(purrr)\ndf &lt;- map_df(df, rescale)\ndf\n#&gt; # A tibble: 5 × 4\n#&gt;       a     b     c     d\n#&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n#&gt; 1  0     1    0.857  0.75\n#&gt; 2  0.25  0.75 1      0.5 \n#&gt; 3  0.5   0.5  0.714  1   \n#&gt; 4  0.75  0.25 0      0.75\n#&gt; 5  1     0    0.286  0\n\n함수를 사용하지 않고 복사하여 붙여넣기 방식으로 코드를 작성한 경우 의도하지 않은 실수가 있어 함수를 도입하여 작성한 코드와 결과가 다른 것이 존재한다. 코드를 읽어 찾아보거나 실행한 후 결과를 통해 버그를 찾아보는 것도 함수의 의미와 중요성을 파악하는데 도움이 된다.\n\n\n\n\n\n\n좋은 함수란?\n\n\n\n척도를 일치시키는 기능을 함수로 구현했지만, 기능을 구현했다고 좋은 함수가 되지는 않는다. 좋은 함수가 되는 조건은 다음과 같다.\n\n\nCorrect: 기능이 잘 구현되어 올바르게 동작할 것\n\nUnderstandable: 사람이 이해할 수 있어야 함. 즉, 함수는 컴퓨터를 위해 기능이 올바르게 구현되고, 사람도 이해할 수 있도록 작성되어야 한다.\n즉, Correct + Understandable: 컴퓨터와 사람을 위해 적성될 것.\n\n한걸음 더 들어가 구체적으로 좋은 함수는 다음과 같은 특성을 지니고 있다.\n\n함수와 인자에 대해 유의미한 명칭을 사용한다.\n\n함수명에 적절한 동사명을 사용한다.\n\n\n직관적으로 인자를 배치하고 기본디폴트값에도 추론가능한 값을 사용한다.\n함수가 인자로 받아 반환하는 것을 명확히 한다.\n함수 내부 몸통부문에 일관된 스타일을 잘 사용한다.\n\n좋은 함수 작성과 연계하여 깨끗한 코드(Clean code)는 다음과 같은 특성을 갖고 작성된 코드를 뜻한다.\n\n가볍고 빠르다 - Light\n가독성이 좋다 - Readable\n해석가능하다 - Interpretable\n유지보수가 뛰어나다 - Maintainable",
    "crumbs": [
      "**5부** 프로그래밍",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>함수</span>"
    ]
  },
  {
    "objectID": "functions.html#how-to-write-function",
    "href": "functions.html#how-to-write-function",
    "title": "\n16  함수\n",
    "section": "\n16.7 사례: rescale 함수",
    "text": "16.7 사례: rescale 함수\n함수를 작성할 경우 먼저 매우 단순한 문제에서 출발한다. 척도를 맞추는 상기 과정을 R 함수로 만드는 과정을 통해 앞서 학습한 사례를 실습해 보자.\n\n입력값과 출력값을 정의한다. 즉, 입력값이 c(1,2,3,4,5) 으로 들어오면 출력값은 0.00 0.25 0.50 0.75 1.00 0–1 사이 값으로 나오는 것이 확인되어야 하고, 각 원소값도 출력벡터 원소값에 매칭이 되는지 확인한다.\n기능이 구현되어 동작이 제대로 되는지 확인되는 R코드를 작성한다.\n\n\n(df$a - min(df$a, na.rm = TRUE)) / (max(df$a, na.rm = TRUE) - min(df$a, na.rm = TRUE))\n\n\n확장가능하게 임시 변수를 사용해서 위에서 구현된 코드를 다시 작성한다.\n\n\n( x - min( x , na.rm = TRUE)) / (max( x , na.rm = TRUE) - min( x , na.rm = TRUE))\n\n\nx &lt;- df$a\n( x - min( x , na.rm = TRUE)) / (max( x , na.rm = TRUE) - min( x , na.rm = TRUE))\n\n\n함수 작성의도를 명확히 하도록 다시 코드를 작성한다.\n\n\nx &lt;- df$a\nrng &lt;- range(x, na.rm = TRUE)\n(x - rng[1]) / (rng[2] - rng[1])\n\n\n최종적으로 재작성한 코드를 함수로 변환한다.\n\n\nx &lt;- df$a\n\nrescale &lt;- function(x){\n                rng &lt;- range(x, na.rm = TRUE)\n                (x - rng[1]) / (rng[2] - rng[1])\n            }\n\nrescale(x)",
    "crumbs": [
      "**5부** 프로그래밍",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>함수</span>"
    ]
  },
  {
    "objectID": "functions.html#function-is-argument",
    "href": "functions.html#function-is-argument",
    "title": "\n16  함수\n",
    "section": "\n16.8 사례: 요약통계 함수",
    "text": "16.8 사례: 요약통계 함수\n데이터를 분석할 때 가장 먼저 수행하는 작업이 요약통계를 통해 데이터를 이해하는 것이다. 이미 훌륭한 요약통계 패키지와 함수가 있지만, 친숙한 개념을 함수로 다시 제작함으로써 함수에 대한 이해를 높일 수 있다.\n요약통계 기능을 먼저 구현한 다음에 중복 제거하여 요약통계 기능 함수를 제작해보자. 함수도 인자로 넣어 처리할 수 있다는 점이 처음에 이상할 수도 있지만, 함수를 인자로 처리할 경우 코드 중복을 상당히 줄일 수 있다. \\(L_1\\), \\(L_2\\), \\(L_3\\) 값을 구하는 함수를 다음과 같이 작성하는 경우, 숫자 1,2,3 만 차이날 뿐 다른 부분은 동일하기 때문에 함수 코드에 중복이 심하게 관찰된다.\n\n1단계: 중복이 심한 함수, 기능 구현에 초점을 맞춤\n\n\nf1 &lt;- function(x) abs(x - mean(x)) ^ 1\nf2 &lt;- function(x) abs(x - mean(x)) ^ 2\nf3 &lt;- function(x) abs(x - mean(x)) ^ 3\n\n\n2단계: 임시 변수로 처리할 수 있는 부분을 식별하고 적절한 인자명(power)을 부여한다.\n\n\nf1 &lt;- function(x) abs(x - mean(x)) ^ power\nf2 &lt;- function(x) abs(x - mean(x)) ^ power\nf3 &lt;- function(x) abs(x - mean(x)) ^ power\n\n\n3단계: 식별된 변수명을 함수 인자로 변환한다.\n\n\nf1 &lt;- function(x, power) abs(x - mean(x)) ^ power\nf2 &lt;- function(x, power) abs(x - mean(x)) ^ power\nf3 &lt;- function(x, power) abs(x - mean(x)) ^ power\n\n여기서 요약통계함수 인자로 “데이터”(df)와 기초통계 요약 “함수”(mean, sd 등)도 함께 넘겨 요약통계함수를 간략하고 가독성 높게 작성할 수 있다.\n먼저, 특정 변수의 중위수, 평균, 표준편차를 계산하는 함수를 작성하는 경우를 가정해보자.\n\n1 단계: 각 기능을 구현하는 기능 구현에 초점을 맞춤\n\n\ncol_median &lt;- function(df) {\n    output &lt;- numeric(length(df))\n    for (i in seq_along(df)) {\n      output[i] &lt;- median(df[[i]])\n    }\n    output\n  }\n\ncol_mean &lt;- function(df) {\n    output &lt;- numeric(length(df))\n    for (i in seq_along(df)) {\n      output[i] &lt;- mean(df[[i]])\n    }\n    output\n  }\n\ncol_sd &lt;- function(df) {\n    output &lt;- numeric(length(df))\n    for (i in seq_along(df)) {\n      output[i] &lt;- sd(df[[i]])\n    }\n    output\n  }\n\n\n2 단계: median, mean, sd를 함수 인자 fun 으로 함수명을 통일.\n\n\ncol_median &lt;- function(df) {\n    output &lt;- numeric(length(df))\n    for (i in seq_along(df)) {\n      output[i] &lt;- fun(df[[i]])\n    }\n    output\n  }\n\ncol_mean &lt;- function(df) {\n    output &lt;- numeric(length(df))\n    for (i in seq_along(df)) {\n      output[i] &lt;- fun(df[[i]])\n    }\n    output\n  }\n\ncol_sd &lt;- function(df) {\n    output &lt;- numeric(length(df))\n    for (i in seq_along(df)) {\n      output[i] &lt;- fun(df[[i]])\n    }\n    output\n  }\n\n\n3 단계: 함수 인자 fun 을 넣어 중복을 제거.\n\n\ncol_median &lt;- function(df, fun) {\n    output &lt;- numeric(length(df))\n    for (i in seq_along(df)) {\n      output[i] &lt;- fun(df[[i]])\n    }\n    output\n  }\n\ncol_mean &lt;- function(df, fun) {\n    output &lt;- numeric(length(df))\n    for (i in seq_along(df)) {\n      output[i] &lt;- fun(df[[i]])\n    }\n    output\n  }\n\ncol_sd &lt;- function(df, fun) {\n    output &lt;- numeric(length(df))\n    for (i in seq_along(df)) {\n      output[i] &lt;- fun(df[[i]])\n    }\n    output\n  }\n\n\n4 단계: 함수를 인자로 갖는 요약통계 함수를 최종적으로 정리하고, 테스트 사례를 통해 검증.\n\n\ncol_summary &lt;- function(df, fun) {\n    output &lt;- numeric(length(df))\n    for (i in seq_along(df)) {\n      output[i] &lt;- fun(df[[i]])\n    }\n    output\n}\n\ncol_summary(df, fun = median)\n#&gt; [1] 0.5000000 0.5000000 0.7142857 0.7500000\ncol_summary(df, fun = mean)\n#&gt; [1] 0.5000000 0.5000000 0.5714286 0.6000000\ncol_summary(df, fun = sd)\n#&gt; [1] 0.3952847 0.3952847 0.4164966 0.3791438",
    "crumbs": [
      "**5부** 프로그래밍",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>함수</span>"
    ]
  },
  {
    "objectID": "ingest_web.html",
    "href": "ingest_web.html",
    "title": "25  웹 데이터",
    "section": "",
    "text": "25.1 엑셀\n제21대 국회의원 선거 당선인 명부 데이터를 엑셀 형태로 구하려면, 선관위 자료공간 웹사이트 게시판을 통해 엑셀 파일을 다운로드할 수 있다.\n다운로드 받은 엑셀 데이터를 가져오는 코드를 목록 25.1 와 같이 작성할 수 있다. 먼저, library(readxl)과 library(tidyverse)를 통해 필요한 패키지를 로드한다. nec_sheets &lt;- readxl::excel_sheets(...)는 엑셀 파일의 시트 이름을 가져오는 코드로 엑셀 파일에서 가져올할 시트를 선택한다. winner_raw &lt;- readxl::read_excel(...)는 선택한 시트의 데이터를 읽어오는 코드로 당선인 명부 데이터를 R 환경으로 불러온다.\n이후, winner_raw |&gt; count(소속정당명, name = \"당선인수\", sort = TRUE)는 파이프 연산자(|&gt;)를 사용하여 데이터를 조작하여 정당별로 집계하고, 당선인 수를 계산한 후, 결과를 내림차순으로 정렬하여 당선인 수를 쉽게 파악할 수 있다. janitor::adorn_totals(where = \"row\", name = \"합계\")는 janitor 패키지 함수로, 집계 결과에 총합 행을 추가하여 전체 당선인 수를 확인할 수 있다.\nlibrary(readxl)\nlibrary(tidyverse)\n\nnec_sheets &lt;- readxl::excel_sheets(\"data/nec/제21대_국회의원선거(재보궐선거_포함)_당선인명부.xlsx\")\n\nwinner_raw &lt;- readxl::read_excel(\"data/nec/제21대_국회의원선거(재보궐선거_포함)_당선인명부.xlsx\", sheet = nec_sheets[1])\n\nwinner_raw |&gt; \n  count(소속정당명, name = \"당선인수\", sort = TRUE) |&gt; \n    janitor::adorn_totals(where = \"row\", name = \"합계\")  \n#&gt;    소속정당명 당선인수\n#&gt;  더불어민주당      163\n#&gt;    미래통합당       84\n#&gt;        무소속        5\n#&gt;        정의당        1\n#&gt;          합계      253\n\n\n목록 25.1: 제21대 국회의원 선거 당선인 명부 데이터 불러오기",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>웹 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_web.html#당선인-사례",
    "href": "ingest_web.html#당선인-사례",
    "title": "25  웹 데이터",
    "section": "",
    "text": "25.1.1 엑셀\n제21대 국회의원 선거 당선인 명부 데이터를 엑셀 형태로 구하려면, 선관위 자료공간 웹사이트 게시판을 통해 엑셀 파일을 다운로드할 수 있다.\n\n\n\n\n\n그림 25.2: 선관위 제21대 국회의원 당선인 명부 엑셀파일\n\n\n다운로드 받은 엑셀 데이터를 가져오는 코드를 목록 25.1 와 같이 작성할 수 있다. 먼저, library(readxl)과 library(tidyverse)를 통해 필요한 패키지를 로드한다. nec_sheets &lt;- readxl::excel_sheets(...)는 엑셀 파일의 시트 이름을 가져오는 코드로 엑셀 파일에서 가져올할 시트를 선택한다. winner_raw &lt;- readxl::read_excel(...)는 선택한 시트의 데이터를 읽어오는 코드로 당선인 명부 데이터를 R 환경으로 불러온다.\n이후, winner_raw |&gt; count(소속정당명, name = \"당선인수\", sort = TRUE)는 파이프 연산자(|&gt;)를 사용하여 데이터를 조작하여 정당별로 집계하고, 당선인 수를 계산한 후, 결과를 내림차순으로 정렬하여 당선인 수를 쉽게 파악할 수 있다. janitor::adorn_totals(where = \"row\", name = \"합계\")는 janitor 패키지 함수로, 집계 결과에 총합 행을 추가하여 전체 당선인 수를 확인할 수 있다.\n\n\n\nlibrary(readxl)\nlibrary(tidyverse)\n\nnec_sheets &lt;- readxl::excel_sheets(\"data/nec/제21대_국회의원선거(재보궐선거_포함)_당선인명부.xlsx\")\n\nwinner_raw &lt;- readxl::read_excel(\"data/nec/제21대_국회의원선거(재보궐선거_포함)_당선인명부.xlsx\", sheet = nec_sheets[1])\n\nwinner_raw |&gt; \n  count(소속정당명, name = \"당선인수\", sort = TRUE) |&gt; \n    janitor::adorn_totals(where = \"row\", name = \"합계\")  \n#&gt;    소속정당명 당선인수\n#&gt;  더불어민주당      163\n#&gt;    미래통합당       84\n#&gt;        무소속        5\n#&gt;        정의당        1\n#&gt;          합계      253\n\n\n목록 25.1: 제21대 국회의원 선거 당선인 명부 데이터 불러오기",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>웹 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_web.html#api",
    "href": "ingest_web.html#api",
    "title": "25  웹 데이터",
    "section": "\n25.2 API",
    "text": "25.2 API\n공공데이터포털 중앙선거관리위원회 당선인정보 API를 활용하여 당선인 정보를 프로그래밍을 통해 직접 가져올 수 있다. 아래아한글로 작성된 당선인 정보 조회 서비스 API 명세서를 참고하여 Java, Javascript, C#, PHP, Curl, Objective-C, Python, Nodejs, R 언어로 예제 코드가 작성되어 있어 사용자가 편리하게 API를 활용할 수 있다.\n\n\n\n\n\n그림 25.3: 국가선거정보 - 당선인 정보 조회 서비스 API 명세서\n\n\n공공데이터포털 API 끝점(Endpoint)와 API KEY를 발급받고 API 서비스 신청을 하였다면 다음 단계로 아래아한글 당선인 정보 조회 서비스 API 명세서 내용을 참고하여 코드를 작성한다.\n\n\n\n\n\ngraph LR\n\n  subgraph API 파악\n    A[공공데이터포털&lt;br&gt;API 발급] --&gt; B[API 명세서&lt;br&gt;참고]\n  end\n  \n  subgraph 스크립트 작성\n    B --&gt; C[당선인 정보 API 호출&lt;br&gt;스크립트 작성]\n    B --&gt; D[선거구 정보 API 호출&lt;br&gt;스크립트 작성]\n  end\n  \n  subgraph 함수 작성\n    C --&gt; E[당선인 정보 API 호출&lt;br&gt;함수 제작]\n    D --&gt; F[선거구 정보 API 호출&lt;br&gt;함수 제작]\n  end\n  \n  subgraph 데이터 가져오기 및 저장\n    F --&gt; G[선거구 데이터프레임&lt;br&gt;제작]\n    G --&gt; H[선거구 당선인&lt;br&gt;데이터프레임 제작]\n    H --&gt; I[데이터 저장]\n  end\n  \nE --&gt; H\n\nlinkStyle 8 stroke:red,stroke-width:4px\n\nstyle A fill:#f0f0f0,stroke:#333,stroke-width:2px\nstyle B fill:#f0f0f0,stroke:#333,stroke-width:2px\nstyle C fill:#e0e0e0,stroke:#333,stroke-width:2px\nstyle D fill:#e0e0e0,stroke:#333,stroke-width:2px\nstyle E fill:#d0d0d0,stroke:#333,stroke-width:2px\nstyle F fill:#d0d0d0,stroke:#333,stroke-width:2px\nstyle G fill:#c0c0c0,stroke:#333,stroke-width:2px\nstyle H fill:#c0c0c0,stroke:#333,stroke-width:2px\nstyle I fill:#c0c0c0,stroke:#333,stroke-width:2px\n\n\n\n\n\n\n공공데이터포털에서 제공하는 API를 활용하여 당선인 정보와 선거구 정보를 수집하고 분석에 용이한 형태로 가공하는 과정은 다음과 같다. API 사용을 위해 활용신청과 API KEY 발급을 진행한 후 명세서를 참고하여 API 호출 방법과 반환되는 데이터 형식을 파악한다.\n당선인 정보와 선거구 정보를 가져오기 위한 API 호출 스크립트를 작성하고, 반복을 줄이고 재사용성을 높이기 위해 함수로 변환하는 작업을 수행한다. 선거구 데이터프레임에서 기본정보 즉, 시도명과 선거구명을 작성한 함수 get_winner() 에 전달하여 선거구별 당선인 정보를 데이터프레임으로 가져온다.\n\n25.2.1 스크립트\n\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(tidyverse)\n\nresponse &lt;- GET(\"http://apis.data.go.kr/9760000/WinnerInfoInqireService2/getWinnerInfoInqire\",\n                query = list(sgId = \"20200415\",\n                              sgTypecode = \"2\",\n                              sdName = \"서울특별시\",\n                              sggName = \"종로구\",\n                              pageNo = 1,\n                              numOfRows = 10,\n                              resultType = \"json\",\n                              serviceKey = Sys.getenv('DATA_GO_DECODE_KEY')))\n\nprint(status_code(response))\n#&gt; [1] 200\n\nresponse_list &lt;- content(response, \"text\") |&gt; \n  fromJSON()\n\nresponse_tbl &lt;- response_list$response$body$items$item\n\nresponse_tbl |&gt; \n    select(sgId, sggName, sdName, giho, jdName, name)\n\n#&gt;       sgId sggName     sdName giho       jdName   name\n#&gt; 1 20200415  종로구 서울특별시    1 더불어민주당 이낙연\n\n\n25.2.2 함수\n\nget_winner &lt;- function(sdName = \"서울특별시\", sggName = \"종로구\") {\n    response &lt;- GET(\"http://apis.data.go.kr/9760000/WinnerInfoInqireService2/getWinnerInfoInqire\",\n                query = list(sgId = \"20200415\",\n                              sgTypecode = \"2\",\n                              sdName = sdName,\n                              sggName = sggName,\n                              pageNo = 1,\n                              numOfRows = 1000,\n                              resultType = \"json\",\n                              serviceKey = Sys.getenv('DATA_GO_DECODE_KEY')))\n\n    response_list &lt;- content(response, \"text\") |&gt; \n      fromJSON()\n    \n    response_tbl &lt;- response_list$response$body$items$item |&gt; \n        select(sgId, sggName, sdName, giho, jdName, name)\n    \n    return(response_tbl)\n}\n\nget_winner(\"서울특별시\", \"종로구\")\n\n#&gt;       sgId sggName     sdName giho       jdName   name\n#&gt; 1 20200415  종로구 서울특별시    1 더불어민주당 이낙연\n\n\n25.2.3 선거구\n중앙선거관리위원회 코드정보 API를 활용하여 선거구 정보를 프로그래밍을 통해 가져올 수 있다. 당선인 명부 데이터를 불러올 때 선거구 정보가 필수적이라 이 과정을 생략할 수는 없다. 당선인 정보와 동일하기 때문에 스크립트 제작과정은 생략하고 명세서에 나와 있는 내용을 바탕으로 R 코드를 작성해서 선거구 데이터프레임을 제작한다.\n\nget_precinct &lt;- function(pageNo = 1) {\n  response &lt;- GET(\"http://apis.data.go.kr/9760000/CommonCodeService/getCommonSggCodeList\",\n              query = list(sgId = \"20200415\",\n                            sgTypecode = \"2\",\n                            pageNo =  pageNo,\n                            numOfRows = 1000,\n                            resultType = \"json\",\n                            serviceKey = Sys.getenv('DATA_GO_DECODE_KEY')))\n  \n  response_list &lt;- content(response, \"text\") |&gt; \n    fromJSON()\n  \n  response_tbl &lt;- response_list$response$body$items$item\n  \n  return(response_tbl)\n}\n\nprecinct_raw &lt;- tibble(page = 1:3) |&gt; \n  mutate(data = map(page, get_precinct)) \n\nprecinct_tbl &lt;- precinct_raw |&gt; \n  unnest(data)\n\nprecinct_tbl  |&gt; \n  select(sgId, sdName, sggName, sggJungsu)\n\n#&gt; # A tibble: 30 × 4\n#&gt;    sgId     sdName     sggName      sggJungsu\n#&gt;    &lt;chr&gt;    &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;    \n#&gt;  1 20200415 서울특별시 종로구       1        \n#&gt;  2 20200415 서울특별시 중구성동구갑 1        \n#&gt;  3 20200415 서울특별시 중구성동구을 1        \n#&gt;  4 20200415 서울특별시 용산구       1        \n#&gt;  5 20200415 서울특별시 광진구갑     1        \n#&gt;  6 20200415 서울특별시 광진구을     1        \n#&gt;  7 20200415 서울특별시 동대문구갑   1        \n#&gt;  8 20200415 서울특별시 동대문구을   1        \n#&gt;  9 20200415 서울특별시 중랑구갑     1        \n#&gt; 10 20200415 서울특별시 중랑구을     1        \n#&gt; # ℹ 20 more rows\n#&gt; # ℹ Use `print(n = ...)` to see more rows\n\n\n25.2.4 선거구 당선인\n\nwinners_raw &lt;- precinct_tbl |&gt; \n  mutate(winner = map2(sdName, sggName, get_winner))\n\nwinners_tbl &lt;-winners_raw |&gt; \n  select(winner) |&gt; \n  unnest(winner)\n\nwinners_tbl\n\n#&gt; # A tibble: 253 × 6\n#&gt;    sgId     sggName      sdName     giho  jdName       name  \n#&gt;    &lt;chr&gt;    &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt; \n#&gt;  1 20200415 종로구       서울특별시 1     더불어민주당 이낙연\n#&gt;  2 20200415 중구성동구갑 서울특별시 1     더불어민주당 홍익표\n#&gt;  3 20200415 중구성동구을 서울특별시 1     더불어민주당 박성준\n#&gt;  4 20200415 용산구       서울특별시 2     미래통합당   권영세\n#&gt;  5 20200415 광진구갑     서울특별시 1     더불어민주당 전혜숙\n#&gt;  6 20200415 광진구을     서울특별시 1     더불어민주당 고민정\n#&gt;  7 20200415 동대문구갑   서울특별시 1     더불어민주당 안규백\n#&gt;  8 20200415 동대문구을   서울특별시 1     더불어민주당 장경태\n#&gt;  9 20200415 중랑구갑     서울특별시 1     더불어민주당 서영교\n#&gt; 10 20200415 중랑구을     서울특별시 1     더불어민주당 박홍근\n#&gt; # ℹ 243 more rows\n#&gt; # ℹ Use `print(n = ...)` to see more rows\n\n\n25.2.5 데이터 저장\n\nwinners_tbl |&gt; \n  write_csv(\"data/21st_election_winners.csv\")",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>웹 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_web.html#section",
    "href": "ingest_web.html#section",
    "title": "25  웹 데이터",
    "section": "\n25.4 ",
    "text": "25.4 \n\n# devtools::install_github(\"ropensci/binman\")\n# devtools::install_github(\"ropensci/wdman\")\n# devtools::install_github(\"ropensci/RSelenium\")\n\nlibrary(RSelenium)\nlibrary(tidyverse)\n\n# 1. 데이터 ----\nrem_driver &lt;- rsDriver(browser=\"firefox\")\nremdrv_client &lt;- rem_driver[[\"client\"]]\n\nremdrv_client$navigate(\"http://www.google.com/\")\nSys.sleep(2)\nremdrv_client$close()\n\n\n\n\n\n\n\n자바(Java) 설치 오류\n\n\n\n\njava_check()에서 다음과 같은 에러가 발생했습니다: PATH to JAVA not found. Please check JAVA is installed.",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>웹 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_web.html#동적-웹-페이지",
    "href": "ingest_web.html#동적-웹-페이지",
    "title": "25  웹 데이터",
    "section": "\n25.3 동적 웹 페이지",
    "text": "25.3 동적 웹 페이지\n중앙선거관리위원회 선거통계시스템에서 제공하는 제21대 국회의원선거 당선인 명단을 R과 RSelenium을 활용한 동적 웹 크롤링을 통해 수집하고 정제하는 과정을 살펴본다. RSelenium 패키지를 설치하고 불여우(Firefox) 브라우저를 제어하기 위해 드라이버를 설치하고 선관위 웹사이트로 이동한다.\n다음으로 CSS 선택자(selector)를 이용하여 선거유형, 선거명, 선거코드, 시도 등의 조회조건을 순차적으로 선택하고 클릭 이벤트를 실행하여 검색조건을 완성한 후 검색 버튼을 클릭하여 해당 조건에 맞는 당선인 명단이 포함된 HTML 표를 브라우저에 렌더링한다. 마지막 단계로, 다시 CSS 선택자로 해당 표를 선택하고 getElementAttribute() 함수를 통해 HTML 표를 추출한 다음, rvest 패키지 read_html(), html_table() 함수를 이용하여 HTML 표를 데이터프레임으로 변환하여 tibble 형태로 크롤링 작업을 마무리 힌다.\n과거 RSelenium을 install.packages() 명령어를 통해서 CRAN에서 다운로드를 할 수는 없었으나 이제 CRAN, RSelenium 에서 직접 설치가 가능하고 GitHub rOpenSci 저장소에서 devtools로 설치한다.\n\n# devtools::install_github(\"ropensci/binman\")\n# devtools::install_github(\"ropensci/wdman\")\n# devtools::install_github(\"ropensci/RSelenium\")\n\nlibrary(RSelenium)\nlibrary(tidyverse)\n\n# 1. 데이터 ----\n\nrem_driver &lt;- rsDriver(browser = \"firefox\", port = 4568L)\nremdrv_client &lt;- rem_driver[[\"client\"]]\nremdrv_client$navigate(\"http://info.nec.go.kr/main/showDocument.xhtml?electionId=0000000000&topMenuId=EP&secondMenuId=EPEI01\")\n\n# 선거유형 \"electionType2\" 선택 후 클릭\nelectionType2 &lt;- remdrv_client$findElement(using = \"css selector\", \"#electionType2\")\nelectionType2$clickElement()\n\n# 조회조건: 제21대 선택\nelectionName &lt;- remdrv_client$findElement(using = \"css selector\", \"#electionName &gt; option:nth-child(2)\")\nelectionName$clickElement()\n\n# 조회조건: 제21대 선택 &gt; 국회의원선거\nelectionCode &lt;- remdrv_client$findElement(using = \"css selector\", \"#electionCode &gt; option:nth-child(2)\")\nelectionCode$clickElement()\n\n# 조회조건: 제21대 선택 &gt; 국회의원선거 &gt; 시도 &gt; 서울특별시\ncityCode &lt;- remdrv_client$findElement(using = \"css selector\", \"#cityCode &gt; option:nth-child(2)\")\ncityCode$clickElement()\n\n# 검색 실행\nrunButton &lt;- remdrv_client$findElement(using = \"css selector\", \"#searchBtn\")\nrunButton$clickElement()\n\n# HTML 표 --&gt; 데이터프레임 변환\nwinner_html &lt;- remdrv_client$findElement(\"css\", \"#table01\")$getElementAttribute(\"outerHTML\")[[1]]\n\nwinner_table &lt;- read_html(winner_html) %&gt;%\n  html_table(fill = TRUE) %&gt;%\n  .[[1]] \n\nremdrv_client$close()\n\nwinner_table |&gt; \n  select(-직업, -학력, -경력)\n\n#&gt; # A tibble: 49 × 6\n#&gt;    선거구명     정당명       `성명(한자)`   성별  `생년월일(연령)` `득표수(득표율)`\n#&gt;    &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;            &lt;chr&gt;           \n#&gt;  1 종로구       더불어민주당 이낙연(李洛淵) 남    1952.12.20(67세) 54,902(58.38)   \n#&gt;  2 중구성동구갑 더불어민주당 홍익표(洪翼杓) 남    1967.11.20(52세) 70,387(54.25)   \n#&gt;  3 중구성동구을 더불어민주당 박성준(朴省俊) 남    1969.04.23(50세) 64,071(51.96)   \n#&gt;  4 용산구       미래통합당   권영세(權寧世) 남    1959.02.24(61세) 63,891(47.80)   \n#&gt;  5 광진구갑     더불어민주당 전혜숙(全惠淑) 여    1955.05.05(64세) 56,608(53.68)   \n#&gt;  6 광진구을     더불어민주당 고민정(高旼廷) 여    1979.08.23(40세) 54,210(50.37)   \n#&gt;  7 동대문구갑   더불어민주당 안규백(安圭伯) 남    1961.04.29(58세) 51,551(52.72)   \n#&gt;  8 동대문구을   더불어민주당 장경태(張耿態) 남    1983.10.12(36세) 55,230(54.54)   \n#&gt;  9 중랑구갑     더불어민주당 서영교(徐瑛敎) 여    1964.11.11(55세) 55,185(57.76)   \n#&gt; 10 중랑구을     더불어민주당 박홍근(朴洪根) 남    1969.10.08(50세) 74,131(59.28)   \n#&gt; # ℹ 39 more rows\n#&gt; # ℹ Use `print(n = ...)` to see more rows\n\n\n\n\n\n\n그림 25.4: 동적 웹 페이지 데이터 추출과정\n\n\n\n\n\n\n\n\n자바(Java) 설치 오류\n\n\n\nRSelenium 패키지를 사용하기 위해서는 자바(Java)가 설치되어 있어야 한다. 데이터 과학 PC (Java) - 윈도우 블로그 게시글을 참조하거나 library(multilinguer); install_java() 함수를 사용해서 설치하여 사용할 수 있다.\n\njava_check()에서 다음과 같은 에러가 발생했습니다: PATH to JAVA not found. Please check JAVA is installed.",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>웹 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_web.html#엑셀",
    "href": "ingest_web.html#엑셀",
    "title": "25  웹 데이터",
    "section": "",
    "text": "그림 25.2: 선관위 제21대 국회의원 당선인 명부 엑셀파일",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>웹 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html",
    "href": "ingest_file.html",
    "title": "24  파일 데이터",
    "section": "",
    "text": "24.1 유니코드와 UTF-8\n사람 간의 의사소통은 다양한 기호 체계를 통해 이루어진다. 영어 알파벳, 한글, 한자 등 문자가 의사소통에 사용되는 좋은 예이다. 디지털 환경에서 이러한 의사소통을 가능하게 하는 기술적 장치가 바로 문자 집합과 문자 인코딩 및 디코딩이다.\n컴퓨터 시스템은 이진수 바이트를 기본 단위로 사용한다. 바이트는 파일 형태로 묶이거나 네트워크를 통해 전송되어 다른 시스템에 도달한다. 이 데이터가 사람에게 의미 있는 정보로 전달되기 위해서는 인코딩(부호화)과 디코딩(복호화) 과정을 거쳐야 한다.\n컴퓨터 시스템은 데이터를 바이트(Byte) 형태로 처리한다. 이 바이트 데이터는 이진수, 즉 010101과 같은 형태로 표현되고, 바이트 데이터를 사람이 읽을 수 있는 문자로 변환하는 최초의 표준이 ASCII(아스키)다. 하지만 ASCII는 256개 문자만을 지원하기 때문에, CJK(중국, 일본, 한국)와 같은 동아시아 문화권에서는 그 한계가 명확하다. 이러한 한계를 해결하기 위해 유니코드(Unicode)가 도입되었다. 유니코드는 영문자는 물론이고 지구상의 거의 모든 문자와 기호를 디지털로 표현할 수 있는 방법을 제공한다.\n유니코드(Unicode)는 글자와 코드가 1:1 매핑되어 있는 단순한 코드표에 불과하고 산업 표준으로 일종의 국가 당사자 간 약속이다. 한글이 표현된 유니코드 영역도 위키백과 유니코드 영역에서 찾을 수 있다.",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#spss",
    "href": "ingest_file.html#spss",
    "title": "24  파일 데이터",
    "section": "\n24.2 SPSS",
    "text": "24.2 SPSS\n세종시에 위치한 한국보건사회연구원에서 조사하여 발표하는 한국복지패널데이터는 특이하게도 오픈 파일 형식만 제외하고 상용 통계 패키지가 있어야 열어볼 수 있는 SPSS, STATA, SAS 파일 형식으로 제공되고 있다. 총4가지 종류 파일을 제공하고 있지만 여기서는 다양한 파일 데이터를 불러오는 방법을 중심으로 살펴보기 때문에 가장 단순한 파일만 R 환경으로 불러오는 방법을 살펴보자.\n\n가구용데이터(SAS, SPSS, STATA):koweps_h17_2022_Beta1\n가구원용데이터(SAS, SPSS, STATA):koweps_p17_2022_Beta1\n복지인식설문용데이터(SAS, SPSS, STATA):koweps_wc17_2022_Beta1\n가구용, 가구원용, 복지인식설문용 머지데이터(SAS, SPSS, STATA):koweps_hpwc17_2022_Beta1\n\nSPSS 로 작성된 .sav 파일으로 R 환경으로 불러오기 위해서는 haven 패키지를 로드하여 SPSS (.sav) 데이터 파일을 R로 읽어온다. read_spss() 함수를 사용하여 “koweps_hpwc17_2022_Beta1.sav” 파일을 welfare_raw 데이터 프레임으로 저장한 후, map_chr() 함수를 사용하여 welfare_raw의 각 변수에 대해 attributes(.x)$label을 적용하여 변수의 레이블을 추출하고 후속 작업을 위해서 문자형 벡터로 변환시킨다.\nenframe() 함수를 사용하여 추출된 레이블을 데이터 프레임으로 변환하고, filter() 함수와 str_detect() 함수를 사용하여 “성별”, “종교”, “태어난 연도”, “혼인상태”, “가구원수”라는 키워드가 포함된 변수만 선택한다. pull() 함수를 사용하여 선택된 변수의 이름을 추출하고, setdiff() 함수를 사용하여 정규표현식 작성과정에서 함께 추출된”h1707_6aq6” 변수를 제외시킨 후 demo_vars 변수로 저장한다.\nwelfare_raw 데이터 프레임에서 select() 함수와 all_of() 함수를 사용하여 demo_vars에 해당하는 변수만 선택한 후 set_names() 함수를 사용하여 선택된 변수명을 “성별”, “종교”, “태어난 연도”, “혼인상태”, “가구원수”로 변경한다. str_split()과 dput()을 사용하여 변수 이름을 파이프(|)로 연산으로 한 명령어로 처리한다. janitor 패키지 clean_names() 함수를 사용하여 변수 이름을 깔끔하게 정리하는데, ascii = FALSE 옵션을 사용하여 한글 변수명을 유지한다.\n한국보건사회연구원에서 한국복지패널 데이터가 SPSS로 제공되고 있지만 상용 SPSS 패키지가 없더라도 R 환경에서 haven 패키지와 janitor 패키지를 활용하여 SPSS 데이터를 불러와서 본격적인 분석을 오픈 데이터 분석 및 통계 언어 R로 수행할 준비가 되었다.\n\nlibrary(haven) # install.packages(\"foreign\")\n\n# Read the .sav file\nwelfare_raw &lt;- read_spss(\"data/file/SPSS/koweps_hpwc17_2022_Beta1.sav\")\n\n## 관심 변수 추출\ndemo_vars &lt;- welfare_raw %&gt;%\n  map_chr(~attributes(.x)$label) |&gt; \n    enframe() |&gt; \n    filter(str_detect(value, \"성별|종교|(태어난 연도)|혼인상태|가구원수\")) |&gt; \n    pull(name) |&gt; \n    setdiff(\"h1707_6aq6\") # 기타소비-종교관련비 변수 제거\n\n## 인구통계학적 변수로 구성된 데이터셋\nwelfare_raw %&gt;%\n  select(all_of(demo_vars)) |&gt; \n    set_names(str_split(\"성별|종교|(태어난 연도)|혼인상태|가구원수\", \"\\\\|\")[[1]] |&gt; dput()) |&gt; \n    janitor::clean_names(ascii = FALSE)\n#&gt; c(\"성별\", \"종교\", \"(태어난 연도)\", \"혼인상태\", \"가구원수\"\n#&gt; )\n#&gt; # A tibble: 16,591 × 5\n#&gt;     성별  종교 태어난_연도 혼인상태 가구원수\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1     1     2        1945        2        1\n#&gt;  2     1     1        1948        2        2\n#&gt;  3     1     1        1942        3        1\n#&gt;  4     5     1        1962        1        1\n#&gt;  5     5     2        1963        1        1\n#&gt;  6     5     2        2003        5        1\n#&gt;  7     5     1        1927        1        1\n#&gt;  8     5     2        1934        1        1\n#&gt;  9     1     2        1940        2        1\n#&gt; 10     2     2        1970        3        1\n#&gt; # ℹ 16,581 more rows",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#sas",
    "href": "ingest_file.html#sas",
    "title": "24  파일 데이터",
    "section": "\n24.3 SAS",
    "text": "24.3 SAS\nSAS 통계패키지 koweps_hpwc17_2022_beta1.sas7bdat 파일을 작성된 동일한 한국보건사회연구원에서 한국복지패널 데이터도 haven 패키지를 사용하여 read_sas() 함수를 사용하여 SAS 데이터 파일(.sas7bdat)을 불러온다. 이후 코드는 앞서 SPSS 데이터를 R 인구통계 데이터프레임으로 변환시켜 가져온 것과 동일한 방법으로 진행된다. 즉, 코드를 재사용하게 된다.\n\nlibrary(haven) # install.packages(\"foreign\")\n\nsas_raw &lt;- read_sas(\"data/file/SAS/koweps_hpwc17_2022_Beta1.sas7bdat\")\n\n## 관심 변수 추출\nsas_vars &lt;- sas_raw %&gt;%\n  map_chr(~attributes(.x)$label) |&gt;\n  enframe() |&gt;\n  filter(str_detect(value, \"성별|종교|(태어난 연도)|혼인상태|가구원수\")) |&gt;\n  pull(name) |&gt;\n  setdiff(\"h1707_6aq6\") # 기타소비-종교관련비 변수 제거\n\n## 인구통계학적 변수로 구성된 데이터셋\nsas_raw %&gt;%\n  select(all_of(sas_vars)) |&gt;\n  set_names(str_split(\"성별|종교|(태어난 연도)|혼인상태|가구원수\", \"\\\\|\")[[1]] |&gt; dput()) |&gt;\n  janitor::clean_names(ascii = FALSE)\n#&gt; c(\"성별\", \"종교\", \"(태어난 연도)\", \"혼인상태\", \"가구원수\"\n#&gt; )\n#&gt; # A tibble: 16,591 × 5\n#&gt;     성별  종교 태어난_연도 혼인상태 가구원수\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1     1     2        1945        2        1\n#&gt;  2     1     1        1948        2        2\n#&gt;  3     1     1        1942        3        1\n#&gt;  4     5     1        1962        1        1\n#&gt;  5     5     2        1963        1        1\n#&gt;  6     5     2        2003        5        1\n#&gt;  7     5     1        1927        1        1\n#&gt;  8     5     2        1934        1        1\n#&gt;  9     1     2        1940        2        1\n#&gt; 10     2     2        1970        3        1\n#&gt; # ℹ 16,581 more rows",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#stata",
    "href": "ingest_file.html#stata",
    "title": "24  파일 데이터",
    "section": "\n24.4 STATA",
    "text": "24.4 STATA\nSTATA 통계패키지 koweps_hpwc17_2022_beta1.dta 파일은 SAS 버전과 동일한 한국복지패널 데이터다. R에서 haven 패키지 read_dta() 함수를 사용하여 STATA 데이터 파일(.dta)을 불러올 수 있다. 이후 코드는 앞서 SPSS, SAS 데이터를 R로 가져와 인구통계 데이터프레임으로 변환한 것과 동일한 방법으로 진행된다. 따라서 이전에 작성한 코드를 그대로 재사용할 수 있다.\n\nlibrary(haven) # install.packages(\"haven\")\n\n# STATA 파일 불러오기\nstata_raw &lt;- read_dta(\"data/file/STATA/Koweps_hpwc17_2022_beta1.dta\")\n\n## 관심 변수 추출\nstata_vars &lt;- stata_raw %&gt;%\n  map_chr(~attributes(.x)$label) |&gt;\n  enframe() |&gt;\n  filter(str_detect(value, \"성별|종교|(태어난 연도)|혼인상태|가구원수\")) |&gt;\n  pull(name) |&gt;\n  setdiff(\"h1707_6aq6\") # 기타소비-종교관련비 변수 제거\n\n## 인구통계학적 변수로 구성된 데이터셋\nstata_raw %&gt;%\n  select(all_of(stata_vars)) |&gt;\n  set_names(str_split(\"성별|종교|(태어난 연도)|혼인상태|가구원수\", \"\\\\|\")[[1]] |&gt; dput()) |&gt;\n  janitor::clean_names(ascii = FALSE)\n#&gt; c(\"성별\", \"종교\", \"(태어난 연도)\", \"혼인상태\", \"가구원수\"\n#&gt; )\n#&gt; # A tibble: 16,591 × 5\n#&gt;     성별  종교 태어난_연도 혼인상태 가구원수\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1     1     2        1945        2        1\n#&gt;  2     1     1        1948        2        2\n#&gt;  3     1     1        1942        3        1\n#&gt;  4     5     1        1962        1        1\n#&gt;  5     5     2        1963        1        1\n#&gt;  6     5     2        2003        5        1\n#&gt;  7     5     1        1927        1        1\n#&gt;  8     5     2        1934        1        1\n#&gt;  9     1     2        1940        2        1\n#&gt; 10     2     2        1970        3        1\n#&gt; # ℹ 16,581 more rows",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#아스키-파일",
    "href": "ingest_file.html#아스키-파일",
    "title": "24  파일 데이터",
    "section": "\n24.4 아스키 파일",
    "text": "24.4 아스키 파일\n\n24.4.1 파일 저장\n펭귄 데이터에서 종별로 3마리를 무작위로 추출해서 nine_penguins 데이터프레임을 만든 후에 다양한 형식 아스키 파일로 저장한다. 펭귄 9마리 데이터프레임으로 아스크 파일 형식으로 저장된 다양한 형태(탭 구분자, 콤마 구분자, 고정길이) 데이터를 불러오는 방법을 살펴본다. 구분자로 탭과 콤마가 가장 많이 사용되지만 경우에 따라서는 “;”, “:”, “|” 등 다양한 구분자를 사용할 수 있다.\n\nlibrary(palmerpenguins)\n\nnine_penguins &lt;- palmerpenguins::penguins |&gt; \n    drop_na() |&gt; \n    slice_sample(n = 3, replace = FALSE, by = species) |&gt; \n    select(-bill_depth_mm)\n\n탭 구분자\nwrite_delim() 함수에 delim 인자를 탭으로 명시하여 탭 구분자 아스키 파일로 저장하는 방법과 write_tsv() 함수를 사용하는 방법이 있다. 탭 구분자 파일로 저장하는 동일한 기능을 수행하지만 함수명에서 차이가 난다.\n\nnine_penguins |&gt; \n    # write_tsv(\"data/file/ASCII/nine_penguins.tsv\") |&gt; \n    write_delim(\"data/file/nine_penguins.txt\", delim = \"\\t\") \n\nspecies\tisland\tbill_length_mm\tflipper_length_mm\tbody_mass_g\tsex\tyear\nAdelie\tBiscoe\t35\t190\t3450\tfemale\t2008\nAdelie\tDream\t41.1\t205\t4300\tmale\t2008\nAdelie\tTorgersen\t38.7\t195\t3450\tfemale\t2007\nGentoo\tBiscoe\t49.8\t229\t5950\tmale\t2009\nGentoo\tBiscoe\t45.4\t211\t4800\tfemale\t2007\nGentoo\tBiscoe\t46.1\t211\t4500\tfemale\t2007\nChinstrap\tDream\t48.5\t191\t3400\tmale\t2007\nChinstrap\tDream\t52.2\t197\t3450\tmale\t2009\nChinstrap\tDream\t53.5\t205\t4500\tmale\t2008\nCSV 구분자\nCSV(Comma-Separated Values) 파일은 콤마 구분자를 사용하여 데이터를 저장하는 형식으로 모든 운영체제에서 특별한 별도 프로그램없이 열어볼 수 있다는 장점이 있어 호환성에서 큰 장점이 있지만 파일에 많은 정보가 담기게 되면 파일크기가 커져서 저장공간을 많이 차지한다는 단점이 있다. write_csv() 함수를 사용하여 콤마 구분자 아스키 파일로 저장하는 방법과 write_delim() 함수를 사용하는 방법이 있다. 콤마 구분자 파일로 저장하는 동일한 기능을 수행하지만 함수명에서 차이가 난다.\n\nnine_penguins |&gt; \n    write_csv(\"data/file/nine_penguins.csv\")\n\nspecies,island,bill_length_mm,flipper_length_mm,body_mass_g,sex,year\nAdelie,Biscoe,35,190,3450,female,2008\nAdelie,Dream,41.1,205,4300,male,2008\nAdelie,Torgersen,38.7,195,3450,female,2007\nGentoo,Biscoe,49.8,229,5950,male,2009\nGentoo,Biscoe,45.4,211,4800,female,2007\nGentoo,Biscoe,46.1,211,4500,female,2007\nChinstrap,Dream,48.5,191,3400,male,2007\nChinstrap,Dream,52.2,197,3450,male,2009\nChinstrap,Dream,53.5,205,4500,male,2008\n고정길이 파일\n고정길이 아스키 파일(Fixed-width ASCII file, FWF)은 데이터 저장 및 교환을 위해 초기 컴퓨팅 시대에 개발되었다. 당시에는 데이터 저장 공간이 제한적이었기 때문에 고정길이 파일은 구분자를 사용하지 않고 데이터를 더 촘촘하게 저장할 수 있었고, 하드웨어와 소프트웨어도 고정 길이 레코드 처리에 최적화되어 있었다.\n현재까지도 고정길이 파일은 레거시 시스템과의 호환성, 데이터 무결성 유지, 데이터 밀도 향상, 대용량 데이터 처리 성능 개선 등의 이유로 명맥을 유지하고 있으며, 의료 및 금융 분야에서 고정길이 파일을 데이터 교환 표준으로 활용하기도 한다.\n하지만, 고정길이 파일은 파일 구조를 이해하기 위해 별도 문서나 스키마 정의가 필요하고, 데이터 추가나 수정 시 레코드 길이 조정이 요구되는 단점이 크고, 구분자로 구분되는 구조화된 데이터 형식과 비교하면 사용 편의성이 크게 떨어진다.\nAdelie    Dream     37.6          181            3300     female   2007\nAdelie    Biscoe    35.3          187            3800     female   2007\nAdelie    Biscoe    37.8          174            3400     female   2007\nGentoo    Biscoe    47.4          212            4725     female   2009\nGentoo    Biscoe    49.1          220            5150     female   2008\nGentoo    Biscoe    47.5          209            4600     female   2008\nChinstrap Dream     40.9          187            3200     female   2008\nChinstrap Dream     47.6          195            3850     female   2008\nChinstrap Dream     46            195            4150     female   2007\n\n24.4.2 불러오기\n탭 구분자\nread_delim() 함수에 delim 인자를 탭으로 명시하여 탭 구분자 아스키 파일을 불러오는 방법과 read_tsv()` 함수를 사용하는 방법이 있다. 탭 구분자 파일을 불러오는 동일한 기능을 수행하지만 함수명에서 차이가 난다.\n\nnine_penguins &lt;- \n    # read_tsv(\"data/file/ASCII/nine_penguins.tsv\") |&gt; \n    read_delim(\"data/file/nine_penguins.txt\", delim = \"\\t\") \n\nCSV 구분자\n고정길이 파일\nreadr 패키지 read_fwf() 함수를 사용하여 고정길이 파일을 불러읽어오는 방식에서 fwf_widths 인자로 각 열의 길이를 지정하고 col_names 인자로 열 이름을 지정한다.\n\nnine_penguins_fwf &lt;-read_fwf(\"data/file/nine_penguins.fwf\",\n                             skip = 0,\n         col_positions = fwf_widths(c(10, 10, 14, 15, 9, 9, 5),\n           col_names = c(\"species\", \"island\", \"bill_length_mm\",\n                         \"flipper_length_mm\", \"body_mass_g\", \"sex\", \"year\")))\n\nnine_penguins_fwf\n#&gt; # A tibble: 9 × 7\n#&gt;   species   island bill_length_mm flipper_length_mm body_mass_g sex     year\n#&gt;   &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 Adelie    Dream            37.6               181        3300 female  2007\n#&gt; 2 Adelie    Biscoe           35.3               187        3800 female  2007\n#&gt; 3 Adelie    Biscoe           37.8               174        3400 female  2007\n#&gt; 4 Gentoo    Biscoe           47.4               212        4725 female  2009\n#&gt; 5 Gentoo    Biscoe           49.1               220        5150 female  2008\n#&gt; 6 Gentoo    Biscoe           47.5               209        4600 female  2008\n#&gt; 7 Chinstrap Dream            40.9               187        3200 female  2008\n#&gt; 8 Chinstrap Dream            47.6               195        3850 female  2008\n#&gt; 9 Chinstrap Dream            46                 195        4150 female  2007",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#불러오기",
    "href": "ingest_file.html#불러오기",
    "title": "24  파일 데이터",
    "section": "\n24.6 불러오기",
    "text": "24.6 불러오기\n\n24.6.1 탭 구분자\n\n24.6.2 CSV 구분자\n\n24.6.3 고정길이 파일\n\n\nnine_penguins_fwf &lt;-read_fwf(\"data/file/nine_penguins.fwf\",\n                             skip = 0,\n         col_positions = fwf_widths(c(10, 10, 14, 15, 9, 9, 5),\n           col_names = c(\"species\", \"island\", \"bill_length_mm\",\n                         \"flipper_length_mm\", \"body_mass_g\", \"sex\", \"year\")))\n\nnine_penguins_fwf\n#&gt; # A tibble: 9 × 7\n#&gt;   species   island bill_length_mm flipper_length_mm body_mass_g sex     year\n#&gt;   &lt;chr&gt;     &lt;chr&gt;           &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;\n#&gt; 1 Adelie    Dream            37.6               181        3300 female  2007\n#&gt; 2 Adelie    Biscoe           35.3               187        3800 female  2007\n#&gt; 3 Adelie    Biscoe           37.8               174        3400 female  2007\n#&gt; 4 Gentoo    Biscoe           47.4               212        4725 female  2009\n#&gt; 5 Gentoo    Biscoe           49.1               220        5150 female  2008\n#&gt; 6 Gentoo    Biscoe           47.5               209        4600 female  2008\n#&gt; 7 Chinstrap Dream            40.9               187        3200 female  2008\n#&gt; 8 Chinstrap Dream            47.6               195        3850 female  2008\n#&gt; 9 Chinstrap Dream            46                 195        4150 female  2007",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#통계패키지",
    "href": "ingest_file.html#통계패키지",
    "title": "24  파일 데이터",
    "section": "\n24.5 통계패키지",
    "text": "24.5 통계패키지\nSPSS, SAS, STATA는 널리 사용되는 통계 분석 소프트웨어 패키지로, 각각 고유한 파일 형식을 사용한다. 고유한 파일 형식을 갖게 되면 데이터가 통계 패키지 내부에서 원활히 동작할 수 있는 메타 정보를 담을 수 있고 속도 향상도 기대할 수 있다. 그러나 이러한 독점적인 파일 형식은 다른 통계 패키지와의 상호 운용성을 제한할 수 있고, 장기적으로 데이터 보존 및 이식성에 문제를 일으킬 수 있다.\nSPSS는 .sav 확장자를 사용하는 이진 파일 형식을 사용한다. .sav 파일은 데이터, 변수 레이블, 값 레이블 등의 메타데이터를 포함하고 있다. SPSS .por 확장자를 가진 파일은 다른 시스템으로 이식도 가능하다.\nSAS는 .sas7bdat 확장자를 사용하는 이진 파일 형식을 사용한다. .sas7bdat 파일은 데이터와 메타데이터를 모두 포함하며, SAS에서만 읽을 수 있다. SAS도 SPSS .por처럼 .xpt 확장자를 가진 다른 시스템에 이식 가능한 파일 형식도 지원한다.\nSTATA는 .dta 확장자를 사용하는 이진 파일 형식을 사용한다. .dta 파일에는 데이터, 변수 레이블, 값 레이블 등 메타데이터가 포함되어 있다. .dta 파일은 STATA에서만 읽을 수 있고 SAS, SPSS에서 읽을 수는 없다 하지만, ‘SAS STATA Transfer’ 프로시저를 ’SPSS Data Access Pack’을 구매하여 STATA 파일을 불러읽을 수 있으며, STATA에서 CSV 파일 형태로 내보낸 후 별도 프로시저나 팩없이 SPSS, SAS에서 불러읽을 수 있는 방법이 있다.\n하지만, 통계 패키지 간에 데이터를 교환하려면 일반적으로 .csv(쉼표로 분리된 값) 또는 .txt(탭으로 분리된 값) 형식과 같은 중간 파일 형식을 사용하는 과정에서 변수 레이블과 값 레이블과 같은 일부 메타데이터가 손실될 수 있다.\n따라서, 단기적으로 SAS/SPSS/STATA와 같은 독점 파일 형식이 제공하는 장점보다 개방형 파일 형식이 장기적으로 데이터 접근성과 재사용성을 높일 수 있다는 면에서 장점이 크다.\n\n24.5.1 SPSS\n세종시에 위치한 한국보건사회연구원에서 조사하여 발표하는 한국복지패널데이터는 특이하게도 오픈 파일 형식만 제외하고 상용 통계 패키지가 있어야 열어볼 수 있는 SPSS, STATA, SAS 파일 형식으로 제공되고 있다. 총4가지 종류 파일을 제공하고 있지만 여기서는 다양한 파일 데이터를 불러오는 방법을 중심으로 살펴보기 때문에 가장 단순한 파일만 R 환경으로 불러오는 방법을 살펴보자.\n\n가구용데이터(SAS, SPSS, STATA):koweps_h17_2022_Beta1\n가구원용데이터(SAS, SPSS, STATA):koweps_p17_2022_Beta1\n복지인식설문용데이터(SAS, SPSS, STATA):koweps_wc17_2022_Beta1\n가구용, 가구원용, 복지인식설문용 머지데이터(SAS, SPSS, STATA):koweps_hpwc17_2022_Beta1\n\nSPSS 로 작성된 .sav 파일으로 R 환경으로 불러오기 위해서는 haven 패키지를 로드하여 SPSS (.sav) 데이터 파일을 R로 읽어온다. read_spss() 함수를 사용하여 “koweps_hpwc17_2022_Beta1.sav” 파일을 welfare_raw 데이터 프레임으로 저장한 후, map_chr() 함수를 사용하여 welfare_raw의 각 변수에 대해 attributes(.x)$label을 적용하여 변수의 레이블을 추출하고 후속 작업을 위해서 문자형 벡터로 변환시킨다.\nenframe() 함수를 사용하여 추출된 레이블을 데이터 프레임으로 변환하고, filter() 함수와 str_detect() 함수를 사용하여 “성별”, “종교”, “태어난 연도”, “혼인상태”, “가구원수”라는 키워드가 포함된 변수만 선택한다. pull() 함수를 사용하여 선택된 변수의 이름을 추출하고, setdiff() 함수를 사용하여 정규표현식 작성과정에서 함께 추출된”h1707_6aq6” 변수를 제외시킨 후 demo_vars 변수로 저장한다.\nwelfare_raw 데이터 프레임에서 select() 함수와 all_of() 함수를 사용하여 demo_vars에 해당하는 변수만 선택한 후 set_names() 함수를 사용하여 선택된 변수명을 “성별”, “종교”, “태어난 연도”, “혼인상태”, “가구원수”로 변경한다. str_split()과 dput()을 사용하여 변수 이름을 파이프(|)로 연산으로 한 명령어로 처리한다. janitor 패키지 clean_names() 함수를 사용하여 변수 이름을 깔끔하게 정리하는데, ascii = FALSE 옵션을 사용하여 한글 변수명을 유지한다.\n한국보건사회연구원에서 한국복지패널 데이터가 SPSS로 제공되고 있지만 상용 SPSS 패키지가 없더라도 R 환경에서 haven 패키지와 janitor 패키지를 활용하여 SPSS 데이터를 불러와서 본격적인 분석을 오픈 데이터 분석 및 통계 언어 R로 수행할 준비가 되었다.\n\nlibrary(haven) # install.packages(\"foreign\")\n\n# Read the .sav file\nwelfare_raw &lt;- read_spss(\"data/file/SPSS/koweps_hpwc17_2022_Beta1.sav\")\n\n## 관심 변수 추출\ndemo_vars &lt;- welfare_raw %&gt;%\n  map_chr(~attributes(.x)$label) |&gt; \n    enframe() |&gt; \n    filter(str_detect(value, \"성별|종교|(태어난 연도)|혼인상태|가구원수\")) |&gt; \n    pull(name) |&gt; \n    setdiff(\"h1707_6aq6\") # 기타소비-종교관련비 변수 제거\n\n## 인구통계학적 변수로 구성된 데이터셋\nwelfare_raw %&gt;%\n  select(all_of(demo_vars)) |&gt; \n    set_names(str_split(\"성별|종교|(태어난 연도)|혼인상태|가구원수\", \"\\\\|\")[[1]] |&gt; dput()) |&gt; \n    janitor::clean_names(ascii = FALSE)\n#&gt; c(\"성별\", \"종교\", \"(태어난 연도)\", \"혼인상태\", \"가구원수\"\n#&gt; )\n#&gt; # A tibble: 16,591 × 5\n#&gt;     성별  종교 태어난_연도 혼인상태 가구원수\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1     1     2        1945        2        1\n#&gt;  2     1     1        1948        2        2\n#&gt;  3     1     1        1942        3        1\n#&gt;  4     5     1        1962        1        1\n#&gt;  5     5     2        1963        1        1\n#&gt;  6     5     2        2003        5        1\n#&gt;  7     5     1        1927        1        1\n#&gt;  8     5     2        1934        1        1\n#&gt;  9     1     2        1940        2        1\n#&gt; 10     2     2        1970        3        1\n#&gt; # ℹ 16,581 more rows\n\n\n24.5.2 SAS\nSAS 통계패키지 koweps_hpwc17_2022_beta1.sas7bdat 파일을 작성된 동일한 한국보건사회연구원에서 한국복지패널 데이터도 haven 패키지를 사용하여 read_sas() 함수를 사용하여 SAS 데이터 파일(.sas7bdat)을 불러온다. 이후 코드는 앞서 SPSS 데이터를 R 인구통계 데이터프레임으로 변환시켜 가져온 것과 동일한 방법으로 진행된다. 즉, 코드를 재사용하게 된다.\n\nlibrary(haven) # install.packages(\"foreign\")\n\nsas_raw &lt;- read_sas(\"data/file/SAS/koweps_hpwc17_2022_Beta1.sas7bdat\")\n\n## 관심 변수 추출\nsas_vars &lt;- sas_raw %&gt;%\n  map_chr(~attributes(.x)$label) |&gt;\n  enframe() |&gt;\n  filter(str_detect(value, \"성별|종교|(태어난 연도)|혼인상태|가구원수\")) |&gt;\n  pull(name) |&gt;\n  setdiff(\"h1707_6aq6\") # 기타소비-종교관련비 변수 제거\n\n## 인구통계학적 변수로 구성된 데이터셋\nsas_raw %&gt;%\n  select(all_of(sas_vars)) |&gt;\n  set_names(str_split(\"성별|종교|(태어난 연도)|혼인상태|가구원수\", \"\\\\|\")[[1]] |&gt; dput()) |&gt;\n  janitor::clean_names(ascii = FALSE)\n#&gt; c(\"성별\", \"종교\", \"(태어난 연도)\", \"혼인상태\", \"가구원수\"\n#&gt; )\n#&gt; # A tibble: 16,591 × 5\n#&gt;     성별  종교 태어난_연도 혼인상태 가구원수\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1     1     2        1945        2        1\n#&gt;  2     1     1        1948        2        2\n#&gt;  3     1     1        1942        3        1\n#&gt;  4     5     1        1962        1        1\n#&gt;  5     5     2        1963        1        1\n#&gt;  6     5     2        2003        5        1\n#&gt;  7     5     1        1927        1        1\n#&gt;  8     5     2        1934        1        1\n#&gt;  9     1     2        1940        2        1\n#&gt; 10     2     2        1970        3        1\n#&gt; # ℹ 16,581 more rows\n\n\n24.5.3 STATA\nSTATA 통계패키지 koweps_hpwc17_2022_beta1.dta 파일은 SAS 버전과 동일한 한국복지패널 데이터다. R에서 haven 패키지 read_dta() 함수를 사용하여 STATA 데이터 파일(.dta)을 불러올 수 있다. 이후 코드는 앞서 SPSS, SAS 데이터를 R로 가져와 인구통계 데이터프레임으로 변환한 것과 동일한 방법으로 진행된다. 따라서 이전에 작성한 코드를 그대로 재사용할 수 있다.\n\nlibrary(haven) # install.packages(\"haven\")\n\n# STATA 파일 불러오기\nstata_raw &lt;- read_dta(\"data/file/STATA/Koweps_hpwc17_2022_beta1.dta\")\n\n## 관심 변수 추출\nstata_vars &lt;- stata_raw %&gt;%\n  map_chr(~attributes(.x)$label) |&gt;\n  enframe() |&gt;\n  filter(str_detect(value, \"성별|종교|(태어난 연도)|혼인상태|가구원수\")) |&gt;\n  pull(name) |&gt;\n  setdiff(\"h1707_6aq6\") # 기타소비-종교관련비 변수 제거\n\n## 인구통계학적 변수로 구성된 데이터셋\nstata_raw %&gt;%\n  select(all_of(stata_vars)) |&gt;\n  set_names(str_split(\"성별|종교|(태어난 연도)|혼인상태|가구원수\", \"\\\\|\")[[1]] |&gt; dput()) |&gt;\n  janitor::clean_names(ascii = FALSE)\n#&gt; c(\"성별\", \"종교\", \"(태어난 연도)\", \"혼인상태\", \"가구원수\"\n#&gt; )\n#&gt; # A tibble: 16,591 × 5\n#&gt;     성별  종교 태어난_연도 혼인상태 가구원수\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1     1     2        1945        2        1\n#&gt;  2     1     1        1948        2        2\n#&gt;  3     1     1        1942        3        1\n#&gt;  4     5     1        1962        1        1\n#&gt;  5     5     2        1963        1        1\n#&gt;  6     5     2        2003        5        1\n#&gt;  7     5     1        1927        1        1\n#&gt;  8     5     2        1934        1        1\n#&gt;  9     1     2        1940        2        1\n#&gt; 10     2     2        1970        3        1\n#&gt; # ℹ 16,581 more rows",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#자료형",
    "href": "ingest_file.html#자료형",
    "title": "24  파일 데이터",
    "section": "\n24.5 자료형",
    "text": "24.5 자료형\n가장 많이 사용되는 콤마 구분자 아스키 파일(.csv) 파일로 불러오면서 함께 고민해야 하는 사항이 바로 자료형이다.\nR에서는 다양한 자료형을 지원한다. 가장 기본적인 자료형은 숫자형, 문자형, 범주형, 논리형이다. 숫자형은 정수형과 실수형으로 구분되며, 문자형은 문자열을 저장하는 자료형이다. 논리형은 참과 거짓을 나타내는 자료형이고, 범주형은 내부적으로 정수로 저장되지만 한정된 범주를 갖는 문자형으로 표현된다. 그외에도 날짜와 시간을 저장하는 자료형, 지도정보를 담고 있는 자료형, 이미지 정보를 담고 있는 자료형 등 다양한 자료형이 있다.\nreadr 패키지 spec() 함수를 사용하면 아스키 파일을 불러읽어 오면서 각 열의 자료형을 확인할 수 있다. spec() 함수에서 출력한 각 열 자료형이 정답은 아니지만 나름 최선의 추정으로 각 열의 자료형을 살펴본 후 최종 열별 자료형을 지정하는데 도움이 되는 것은 사실이다.\n\nspec( read_csv(\"data/file/nine_penguins.csv\") )\n#&gt; cols(\n#&gt;   species = col_character(),\n#&gt;   island = col_character(),\n#&gt;   bill_length_mm = col_double(),\n#&gt;   flipper_length_mm = col_double(),\n#&gt;   body_mass_g = col_double(),\n#&gt;   sex = col_character(),\n#&gt;   year = col_double()\n#&gt; )\n\nreadr 패키지 col_types 인자를 사용하여 각 열의 자료형을 지정할 수 있다. col_types 인자에는 cols() 함수를 사용하여 각 열의 자료형을 지정한다. cols() 함수에는 col_factor(), col_character(), col_double(), col_integer(), col_logical() 함수를 사용하여 각 열의 자료형을 지정한다. col_factor() 함수는 범주형 자료형을 지정할 때 사용하며, col_character() 함수는 문자형 자료형을 지정할 때 사용한다. col_double() 함수는 실수형 자료형을 지정할 때 사용하며, col_integer() 함수는 정수형 자료형을 지정할 때 사용한다. col_logical() 함수는 논리형 자료형을 지정할 때 사용한다.\nspec() 함수가 텍스트로 된 열은 모두 문자형(col_character())으로 인식하였지만, species, sex 열은 범주형 자료형으로 지정하는 것이 더 적절하다. bill_length_mm, flipper_length_mm, body_mass_g, year 열은 실수형, 정수형 자료형으로 지정하는 것이 적절하다고 판단되어 다음과 같이 .csv 파일을 불러오면서 각 열의 자료형도 함께 지정한다.\n\npenguins_tbl &lt;- read_csv(\"data/file/nine_penguins.csv\",\n         col_types = cols(\n            species = col_factor(level = c(\"Adelie\", \"Chinstrap\", \"Gentoo\")),\n            island = col_character(),\n            bill_length_mm = col_double(),\n            flipper_length_mm = col_double(),\n            body_mass_g = col_double(),\n            sex = col_factor(levels = c(\"female\", \"male\")),\n            year = col_integer()\n          )\n)\n\npenguins_tbl\n#&gt; # A tibble: 9 × 7\n#&gt;   species   island    bill_length_mm flipper_length_mm body_mass_g sex     year\n#&gt;   &lt;fct&gt;     &lt;chr&gt;              &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;  &lt;int&gt;\n#&gt; 1 Adelie    Biscoe              35                 190        3450 female  2008\n#&gt; 2 Adelie    Dream               41.1               205        4300 male    2008\n#&gt; 3 Adelie    Torgersen           38.7               195        3450 female  2007\n#&gt; 4 Gentoo    Biscoe              49.8               229        5950 male    2009\n#&gt; 5 Gentoo    Biscoe              45.4               211        4800 female  2007\n#&gt; 6 Gentoo    Biscoe              46.1               211        4500 female  2007\n#&gt; 7 Chinstrap Dream               48.5               191        3400 male    2007\n#&gt; 8 Chinstrap Dream               52.2               197        3450 male    2009\n#&gt; 9 Chinstrap Dream               53.5               205        4500 male    2008",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#유니코드와-utf-8",
    "href": "ingest_file.html#유니코드와-utf-8",
    "title": "24  파일 데이터",
    "section": "",
    "text": "유니코드와 UTF-8\n\n\n\n\n\n\n\n인코딩 (Encoding)\n\n\n\n문자 인코딩(character encoding), 줄여서 인코딩은 사용자가 입력한 문자나 기호들을 컴퓨터가 이용할 수 있는 신호로 만드는 것을 말한다. 넓은 의미의 컴퓨터는 이러한 신호를 입력받고 처리하는 기계를 뜻하며, 신호 처리 시스템을 통해 이렇게 처리된 정보를 사용자가 이해할 수 있게 된다.\n\nAll text has a character encoding.\n\n\n\n\n24.1.1 인코딩 문제\n문자 인코딩은 컴퓨터가 텍스트를 바이트로 변환하거나 바이트를 텍스트로 변환하는 방법이다. 인코딩 과정에서는 다양한 문제가 발생할 수 있고, 그중 세 가지 문제가 많이 알려져 있다. 첫 번째는 ’두부(Tofu)’라 불리는 상황으로, 컴퓨터가 어떤 문자를 표현해야 할지 알지만, 화면에 어떻게 출력해야 할지 모르기 때문에 빈 사각형 상자로 표시된다. 두 번째는 ’문자 깨짐(Mojibake, 文字化け)’이다. 특히 일본어에서 자주 발생하며, 한 인코딩 방식으로 작성된 텍스트가 다른 인코딩 방식으로 해석될 때 문자가 깨지는 현상을 의미한다. 세 번째는 ’의문부호(Question Marks)’로, 특정 문자가 다른 문자로 변환될 때 발생된다. 문자 집합과 인코딩 궁합이 맞지 않을 때 발생하며, 데이터 손실과 오류도 야기된다.\n\n\n세 가지 인코딩 문제",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#문자-집합",
    "href": "ingest_file.html#문자-집합",
    "title": "24  파일 데이터",
    "section": "\n24.2 문자 집합",
    "text": "24.2 문자 집합\n\n24.2.1 아스키 코드\n디지털 글쓰기는 내용과 상관없이 결국 텍스트로 표현되고, 텍스트는 단지 문자이다. 하지만, 컴퓨터가 문자 하나를 어떻게 표현할까?\n1960년대 미국식 영문자를 컴퓨터로 표현하는 해결책은 간단했다. 알파벳 26개(대문자, 소문자), 숫자 10개, 구두점 몇 개, 그리고 전신을 보내던 시절에 제어를 위해 사용된 몇 개의 특수 문자(“새줄로 이동”, “본문 시작”, “경고음” 등)가 전부였다. 모두 합쳐도 128개보다 적어서, 아스키(ASCII) 위원회가 문자마다 7비트( \\(2^7\\) = 128)를 사용하는 인코딩으로 표준화했다. 1\n\n\n\n\n\n그림 24.2: 제어문자와 출력 가능한 아스키 문자표 알파벳 예시\n\n\n그림 24.2 는 아스키 문자표에서 제어문자 10개와 출력 가능한 아스키 문자표 중 영문 대문자 A-I까지 10개를 뽑아 사례로 보여준다. 즉, 문자표는 어떤 문자가 어떤 숫자에 해당하는지를 정의하고 있다.\n\n24.2.2 확장 아스키\n아스키(ASCII) 방식으로 숫자 2, 문자 q, 혹은 곡절 악센트 ^를 표현하는 데 충분하다. 하지만, 투르크어족 추바시어 ĕ, 그리스 문자 β, 러시아 키릴 문자 Я는 어떻게 저장하고 표현해야 할까? 7비트를 사용하면 0에서 127까지 숫자를 부여할 수 있지만, 8비트(즉, 1바이트)를 사용하게 되면 255까지 표현할 수 있다. 그렇다면, ASCII 표준을 확장해서 추가되는 128개 숫자에 대해 추가로 문자를 표현할 수 있게 된다.\n\n아스키: 0…127\n확장된 아스키: 128…255\n\n불행하게도, 영어 문자를 사용하지 않는 세계 곳곳에서 많은 사람들이 시도를 했지만, 방식도 다르고, 호환이 되지 않는 방식으로 작업이 되어, 결과는 엉망진창이 되었다. 예를 들어, 실제 텍스트가 불가리아어로 인코딩되었는데 스페인어 규칙을 사용해서 인코딩한 것으로 프로그램이 간주하고 처리될 경우 결과는 무의미한 횡설수설 값이 출력된다. 이와는 별도로 한중일(CJK) 동아시아 국가들을 비롯한 많은 국가들이 256개 이상의 기호를 사용한다. 왜냐하면 8비트로는 특히 동아시아 국가 문자를 표현하는 데 부족하기 때문이다.\n\n24.2.3 한글 완성형과 조합형\n1980년대부터 컴퓨터를 사용하신 분이라면 완성형과 조합형의 표준화 전쟁을 지켜봤을 것이고, 그 이면에는 한글 워드프로세서에 대한 주도권 쟁탈전이 있었던 것을 기억할 것이다. 결국 완성형과 조합형을 모두 포용하는 것으로 마무리되었지만, 여기서 끝난 게 아니다. 유닉스 계열에서 KSC5601을 표준으로 받아들인 EUC-KR과 90년대와 2000년대를 호령한 마이크로소프트 CP949가 있었다. 결국 대한민국 정부에서 주도한 표준화 전쟁은 유닉스/리눅스, 마이크로소프트 모두를 녹여내는 것으로 마무리되었고, 웹과 모바일 시대는 유니코드로 넘어가서 KSC5601이 유니코드의 원소로 들어가는 것으로 마무리되었다.\n이제 신경 쓸 것은 인코딩, 즉 utf-8만 신경 쓰면 된다. 그리고 남은 디지털 레거시 유산을 잘 처리하면 된다.\n\n\n\n\n\n\n유닉스/리눅스(EUC-KR), 윈도우(CP949)\n\n\n\nEUC-KR, CP949 모두 2바이트 한글을 표현하는 방식으로 동일점이 있지만, EUC-KR 방식은 KSC5601-87 완성형을 초기에 사용하였으나, KSC5601-92 조합형도 사용할 수 있도록 확장되었다. CP949는 확장 완성형으로도 불리며 EUC-KR에서 표현할 수 없는 한글 글자 8,822자를 추가한 것으로 마이크로소프트 코드페이지(Code Page) 949를 사용하면서 일반화되었다.\n\n\n\n24.2.4 유니코드\n1990년대에 나타나기 시작한 해결책을 유니코드(Unicode)라고 부른다. 예를 들어, 영어 A 대문자는 1바이트, 한글 가는 3바이트다. 유니코드는 정수값을 서로 다른 수만 개 문자와 기호를 표현하는 데 정의한다. ’A’는 U+0041, ’가’는 U+AC00과 같이 고유한 코드 포인트를 가진다. 하지만, 파일에 혹은 메모리에 문자열로 정수값을 저장하는 방식을 정의하지는 않는다.\n각 문자마다 8비트를 사용하던 방식에서 32비트 정수를 사용하는 방식으로 전환하면 되지만, 영어, 에스토니아어, 브라질 포르투갈어 같은 알파벳 언어권에는 상당한 공간 낭비가 발생된다. 접근 속도가 중요한 경우 메모리에 문자당 32비트를 종종 사용한다. 하지만, 파일에 데이터를 저장하거나 인터넷을 통해 전송하는 경우 대부분의 프로그램과 프로그래머는 이와는 다른 방식을 사용한다.\n다른 방식은 (거의) 항상 UTF-8으로 불리는 인코딩으로, 문자마다 가변 바이트를 사용한다. 하위 호환성을 위해, 첫 128개 문자(즉, 구 아스키 문자 집합)는 바이트 1개에 저장된다. 다음 1920개 문자는 바이트 2개를 사용해서 저장된다. 다음 61,000개는 바이트 3개를 사용해서 저장해 나간다.\n궁금하다면, 동작 방식이 다음 표에 나타나 있다. “전통적” 문자열은 문자마다 1바이트를 사용한다. 반대로, “유니코드” 문자열은 문자마다 충분한 메모리를 사용해서 어떤 텍스트 유형이든 저장한다. R, 파이썬 3.x에서 모든 문자열은 유니코드다. 엄청난 바이트를 읽어오거나 저장하여 내보내려고 할 때, 인코딩을 지정하는 것은 엄청난 고통이다.\n유니코드 문자열은 여는 인용부호 앞에 소문자 U를 붙여 표시한다. 유니코드 문자열을 바이트 문자열로 전환하려면, 인코딩을 명세해야만 된다. 항상 UTF-8을 사용해야 하고, 그 밖의 인코딩을 사용하는 경우 매우, 매우 특별히 좋은 사유가 있어야만 된다. 특별한 인코딩을 사용하는 경우 두 번 생각해 보라.\n\n\n아스키에서 유니코드로 진화과정\n\n컴퓨터가 처음 등장할 때 미국 영어권 중심 아스키가 아니고 4바이트로 전 세계 모든 글자를 표현할 수 있는 유니코드가 사용되었다면 한글을 컴퓨터에 표현하기 위한 지금과 같은 번거로움은 없었을 것이다. 돌이켜보면 초기 컴퓨터가 저장 용량 한계로 인해 유니코드가 표준으로 자리를 잡더라도 실용적인 이유로 인해서 한글을 컴퓨터에 표현하기 위한 다른 대안이 제시됐을 것도 분명해 보인다. 초창기 영어권을 중심으로 아스키 표준이 정립되어 현재까지 내려오고, 유니코드와 UTF-8 인코딩이 사실상 표준으로 자리 잡았으며, 그 사이 유닉스/리눅스 EUC-KR, 윈도우즈 CP949가 빈틈을 한동안 메우면서 역할을 담당했다.\n\n\n\n\n\n\n\n\n\n항목\nASCII (1963)\nEUC-KR (1980s)\nCP949 (1990s)\nUnicode (1991)\n\n\n\n범위\n128개의 문자\n2,350개의 한글 문자 등\n약 11,172개의 완성형 한글 문자 등\n143,859개의 문자 (버전 13.0 기준)\n\n\n비트 수\n7비트\n8~16비트\n8~16비트\n다양한 인코딩 방식 (UTF-8, UTF-16, UTF-32 등)\n\n\n표준\nANSI, ISO/IEC 646\nKS X 2901\n마이크로소프트\nISO/IEC 10646\n\n\n플랫폼\n다양한 시스템\nUNIX 계열, 일부 Windows\nWindows 계열\n다양한 플랫폼\n\n\n문자 집합\n영문 알파벳, 숫자, 특수 문자\n한글, 영문 알파벳, 숫자, 특수 문자\n한글, 한자, 영문 알파벳, 숫자, 특수 문자\n전 세계 언어, 특수 문자, 이모티콘 등\n\n\n확장성\n확장 불가능\n한정적\n더 많은 문자 지원\n높은 확장성\n\n\n국제성\n영어 중심\n한국어 중심\n한국어 중심\n다국어 지원\n\n\n유니코드 호환\n호환 가능 (U+0000 ~ U+007F)\n호환 불가, 변환 필요\n유니코드와 상호 변환 가능\n자체가 표준\n\n\n\n24.2.5 UTF-8\nUTF-8(Universal Coded Character Set + Transformation Format – 8-bit의 약자)은 유니코드 중에서 가장 널리 쓰이는 인코딩으로, 유니코드를 위한 가변 길이 문자 인코딩 방식 중 하나로 켄 톰프슨과 롭 파이크가 제작했다.\nUTF-8 인코딩의 가장 큰 장점은 아스키(ASCII), 라틴-1(ISO-8859-1)과 호환되어, 문서를 처리하는 경우 아스키, 라틴-1 문서를 변환 없이 그대로 처리할 수 있고 영어를 비롯한 라틴계열 문서로 저장할 때 용량이 매우 작다. 이러한 이유로 많은 오픈소스 소프트웨어와 데이터를 생산하는 미국을 비롯한 유럽 언어권에서 UTF-8이 많이 사용되고 있지만, 한글은 한 글자당 3바이트 용량을 차지한다.\n\n24.2.6 웹 표준 인코딩\n스마트폰의 대중화에 따라 더이상 윈도우 운영체제에서 사용되는 문자체계가 더이상 표준이 되지 못하고 여러 문제점을 야기함에 따라 유니코드 + UTF-8 체제가 대세로 자리잡고 있는 것이 확연히 나타나고 있다.\n2010년 구글에서 발표한 자료에 의하면 2010년 UTF-8 인코딩이 웹에서 주류로 부상하기 시작한 것이 확인되었다. (unicode2010?) 웹 기반 플롯 디지털 도구를 활용하여 그래프(WebPlotDigitizer)에서 데이터를 추출하여 시각화하면 유사한 결과를 시각적으로 표현할 수 있다. 2010년 이후 웹에서 가장 점유율이 높은 인코딩 방식은 UTF-8으로 W3Tech 웹 기술 조사(Web Technology Surveys)를 통해 확인할 수 있다. 여기서 주목할 점은, 프랑스어, 독일어, 스페인어와 같은 서유럽 언어의 문자와 기호를 표현하는 ISO-8859-1 인코딩, 종종 “Latin-1”으로 불리는 8비트 문자 인코딩이 현저히 줄고 있다는 점이다.\n\n\n2010 ~ 2012 웹에서 UTF-8 성장세",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#footnotes",
    "href": "ingest_file.html#footnotes",
    "title": "24  파일 데이터",
    "section": "",
    "text": "미국정보교환표준부호(American Standard Code for Information Interchange, ASCII)는 영문 알파벳을 사용하는 대표적인 문자 인코딩으로 컴퓨터와 통신 장비를 비롯한 문자를 사용하는 많은 장치에서 사용되며, 대부분의 문자 인코딩이 아스키에 기초하고 있다.↩︎",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#인코딩",
    "href": "ingest_file.html#인코딩",
    "title": "24  파일 데이터",
    "section": "\n24.7 인코딩",
    "text": "24.7 인코딩\n공공데이터포털을 비롯한 많은 정부기관에서 제공하는 데이터는 대부분 EUC-KR로 인코딩되어 있다. 이유는 여러가지가 있겠지만 가장 큰 이유는 아마도 엑셀에서 .csv 파일을 열었을 때 한글이 깨지는 민원을 처리하기 위함이 아닐까 싶다. 정형 .csv 파일 형태로 데이터를 받게 되면 먼저 인코딩을 확인해야 한다. readr 패키지의 guess_encoding() 함수를 사용하면 파일의 인코딩을 확인할 수 있다.\n공공데이터포털 인천광역시_정류장별 이용승객 현황 데이터를 다운로드 받아 로컬 파일로 저장한 후 인코딩을 확인한다.\n\nlibrary(readr)\n\nfile_path &lt;- \"data/file/인천광역시_정류장별 이용승객 현황_20220630.csv\"\nguess_encoding(file_path)\n#&gt; # A tibble: 4 × 2\n#&gt;   encoding confidence\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1 EUC-KR         1   \n#&gt; 2 GB18030        0.81\n#&gt; 3 Big5           0.48\n#&gt; 4 EUC-JP         0.3\n\n따라서, 이를 바로 read_csv() 함수로 읽을 경우 오류가 발생된다. 왜냐하면 read_csv() 함수는 인코딩을 UTF-8을 기본으로 가정하고 있기 때문이다.\n\nread_csv(file_path)\n#&gt; Error in nchar(x, \"width\"): invalid multibyte string, element 1",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#공공-데이터",
    "href": "ingest_file.html#공공-데이터",
    "title": "24  파일 데이터",
    "section": "\n24.6 공공 데이터",
    "text": "24.6 공공 데이터\n공공데이터포털을 비롯한 많은 정부기관에서 제공하는 데이터는 대부분 EUC-KR로 인코딩되어 있다. 이유는 여러가지가 있겠지만 가장 큰 이유는 아마도 엑셀에서 .csv 파일을 열었을 때 한글이 깨지는 민원을 처리하기 위함이 아닐까 싶다. 정형 .csv 파일 형태로 데이터를 받게 되면 먼저 인코딩을 확인해야 한다. readr 패키지의 guess_encoding() 함수를 사용하면 파일의 인코딩을 확인할 수 있다.\n공공데이터포털 인천광역시_정류장별 이용승객 현황 데이터를 다운로드 받아 로컬 파일로 저장한 후 인코딩을 확인한다.\n\nlibrary(readr)\n\nfile_path &lt;- \"data/file/인천광역시_정류장별 이용승객 현황_20220630.csv\"\nguess_encoding(file_path)\n#&gt; # A tibble: 4 × 2\n#&gt;   encoding confidence\n#&gt;   &lt;chr&gt;         &lt;dbl&gt;\n#&gt; 1 EUC-KR         1   \n#&gt; 2 GB18030        0.81\n#&gt; 3 Big5           0.48\n#&gt; 4 EUC-JP         0.3\n\n따라서, 이를 바로 read_csv() 함수로 읽을 경우 오류가 발생된다. 왜냐하면 read_csv() 함수는 인코딩을 UTF-8을 기본으로 가정하고 있기 때문이다.\n\nread_csv(file_path)\n#&gt; Error in nchar(x, \"width\"): invalid multibyte string, element 1\n\n따라서, read_csv() 함수를 사용할 때는 locale 인수를 사용하여 인코딩을 지정해주어야 한다. “EUC-KR”로 인코딩을 지정하면 파일을 오류없이 읽을 수 있다.\n\nincheon_bus &lt;- spec(read_csv(file_path, locale = locale(encoding = \"EUC-KR\")))\nincheon_bus |&gt; names() |&gt; dput()\n#&gt; c(\"cols\", \"default\", \"delim\")\n\n데이터 가져오기는 데이터 분석의 첫 단계로, 외부 데이터를 R로 불러오는 과정으로 첫단추가 이후 이어질 분석단계에서 중요한 역할을 한다.\n먼저, 파일 형식에 따라 적절한 함수를 선택해야 한다. 텍스트 파일은 read.csv, read.table 등의 함수를 사용하고, 엑셀 파일은 readxl 패키지의 read_excel 함수를 사용한다. 특히, 인코딩도 이 단계에서 반듯이 확인해야 한다.\n데이터 전처리 단계에서는 구분자와 헤더 유무를 확인하고, 자료형과 칼럼명을 결정해야 한다. 결측값 처리를 위해 na = 옵션을 사용할 수 있고, 필요에 따라 특정 행/열을 선택하는 등의 추가 옵션을 설정할 수 있다.\n전처리 과정을 거쳐 최종적으로 데이터프레임을 생성하게 된다. 다소 번거럽더라도 데이터를 가져오는 단계에서 전처리 과정을 충실히 수행하게 되면 이후 dplyr, tidyr 패키지 등을 활용해 다양한 데이터 조작 및 시각화를 수월하게 할 수 있다.\n\nfile_path &lt;- \"data/file/인천광역시_정류장별 이용승객 현황_20220630.csv\"\n\nincheon_bus &lt;- read_csv(file_path, locale = locale(encoding = \"EUC-KR\"),\n                        skip = 1,\n                        na = c(\"---\", \"\"),\n                        col_names = c(\"정류소명\", \"정류소_id\", \"승차건수_총합계\", \n                                     \"하차건수_총합계\",\"승차건수_카드\", \"하차건수_카드\",\n                                     \"승차건수_현금\", \"일평균_승하차건수\"),\n                       col_types = cols(\n                         정류소명 = col_character(),\n                         정류소_id = col_double(),\n                         승차건수_총합계 = col_double(),\n                         하차건수_총합계 = col_double(),\n                         승차건수_카드 = col_double(),\n                         하차건수_카드 = col_double(),\n                         승차건수_현금 = col_double(),\n                         일평균_승하차건수 = col_double()\n                       ))  \nincheon_bus\n#&gt; # A tibble: 6,386 × 8\n#&gt;    정류소명             정류소_id 승차건수_총합계 하차건수_총합계 승차건수_카드\n#&gt;    &lt;chr&gt;                    &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;         &lt;dbl&gt;\n#&gt;  1 (구)국제여객터미널       35051              95            1923            21\n#&gt;  2 (구)국제여객터미널          NA            2512              43          2465\n#&gt;  3 (주)경동세라믹스         89146             341              26           335\n#&gt;  4 (주)경인양행앞           42096             945             923           938\n#&gt;  5 (주)경인양행앞           42097            1322            3536          1294\n#&gt;  6 (주)대한특수금속         39050            1243              89          1238\n#&gt;  7 (주)두남                 39135             147              29           147\n#&gt;  8 (주)세모입구(린나이…     37585            1410            1517          1404\n#&gt;  9 (주)세모입구(린나이…     40893             307             556           304\n#&gt; 10 (주)스킨이데아           89388             147             148           147\n#&gt; # ℹ 6,376 more rows\n#&gt; # ℹ 3 more variables: 하차건수_카드 &lt;dbl&gt;, 승차건수_현금 &lt;dbl&gt;,\n#&gt; #   일평균_승하차건수 &lt;dbl&gt;\n\n지금까지 작업한 전반적인 작업흐름은 그림 24.4 에 대략적으로 나와있다. 공공데이터포털에서 다운로드 받은 인천광역시_정류장별 이용승객 현황_20220630.csv은 EUC-KR로 인코딩 되어 있고 헤더를 갖고 있으며 쉼표로 구분되어 있다. 결측치는 없으나 임의로 --- 으로 정류장 한 곳을 달리 표현하여 na = c(\"---\", \"\")로 결측값 처리를 하였다.\n\n\n\n\n\ngraph LR\n    subgraph \"&lt;strong&gt;파일 형식 결정&lt;/strong&gt;\"\n    A[파일 형식 결정] --&gt; |\"read.csv, read.table 등\"| B[인코딩 확인]\n    A --&gt; |\"readxl::read_excel 등\"| B\n    end\n\n    subgraph \"&lt;strong&gt;데이터 전처리&lt;/strong&gt;\"\n    C[구분자 확인] --&gt; |\"쉼표, 탭 등\"| B\n    D[헤더 유무] --&gt; |\"header = TRUE/FALSE\"| B\n    B --&gt; E[자료형 및&lt;br&gt; 칼럼명 결정]\n    F[결측값 처리] --&gt; |\"na 옵션\"| E\n    G[추가 옵션] --&gt; |\"특정 행/열 선택 등\"| E\n    end\n\nE --&gt; H[데이터프레임&lt;br&gt;생성]\n\nstyle A fill:#f0f0f0,stroke:#333,stroke-width:2px\nstyle B fill:#f0f0f0,stroke:#333,stroke-width:2px\nstyle C fill:#e0e0e0,stroke:#333,stroke-width:2px\nstyle D fill:#e0e0e0,stroke:#333,stroke-width:2px\nstyle E fill:#d0d0d0,stroke:#333,stroke-width:2px\nstyle F fill:#d0d0d0,stroke:#333,stroke-width:2px\nstyle G fill:#c0c0c0,stroke:#333,stroke-width:2px\nstyle H fill:#c0c0c0,stroke:#333,stroke-width:2px\n\n\n\n\n그림 24.4: 인천광역시 정류장별 이용승객 현황 데이터 데이터프레임 가져오는 과정",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_file.html#데이터-종류",
    "href": "ingest_file.html#데이터-종류",
    "title": "24  파일 데이터",
    "section": "\n24.3 데이터 종류",
    "text": "24.3 데이터 종류\n\n\n\n\n\ngraph TB\n    subgraph 가져오기[\"가져오기(Import)\"]\n        csv[CSV 파일] --&gt; 핸들러\n        스프레드쉬트 --&gt; 핸들러\n        데이터베이스 --&gt; 핸들러\n        웹 --&gt; 핸들러\n\n        핸들러 --&gt; 데이터프레임\n    end\n    \n    classDef modern fill:#fff,stroke:#333,stroke-width:2px,color:#333,font-family:MaruBuri,font-size:12px;\n    classDef emphasize fill:#8CBDE3,stroke:#333,stroke-width:3px,color:#333,font-family:MaruBuri,font-size:15px,font-weight:bold;\n    classDef subgraphStyle fill:#f0f8ff,stroke:#333,stroke-width:2px,color:#333,font-family:MaruBuri,font-size:20px;\n    \n    class csv,스프레드쉬트,데이터베이스,웹,핸들러 modern\n    class 데이터프레임 emphasize\n    class 가져오기 subgraphStyle\n\n\n\n\n그림 24.3: 다양한 데이터 종류",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>파일 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_spreadsheet.html",
    "href": "ingest_spreadsheet.html",
    "title": "26  상용 데이터",
    "section": "",
    "text": "26.1 통계패키지\nSPSS, SAS, STATA는 널리 사용되는 통계 분석 소프트웨어 패키지로, 각각 고유한 파일 형식을 사용한다. 고유한 파일 형식을 갖게 되면 데이터가 통계 패키지 내부에서 원활히 동작할 수 있는 메타 정보를 담을 수 있고 속도 향상도 기대할 수 있다. 그러나 이러한 독점적인 파일 형식은 다른 통계 패키지와의 상호 운용성을 제한할 수 있고, 장기적으로 데이터 보존 및 이식성에 문제를 일으킬 수 있다.\nSPSS는 .sav 확장자를 사용하는 이진 파일 형식을 사용한다. .sav 파일은 데이터, 변수 레이블, 값 레이블 등의 메타데이터를 포함하고 있다. SPSS .por 확장자를 가진 파일은 다른 시스템으로 이식도 가능하다.\nSAS는 .sas7bdat 확장자를 사용하는 이진 파일 형식을 사용한다. .sas7bdat 파일은 데이터와 메타데이터를 모두 포함하며, SAS에서만 읽을 수 있다. SAS도 SPSS .por처럼 .xpt 확장자를 가진 다른 시스템에 이식 가능한 파일 형식도 지원한다.\nSTATA는 .dta 확장자를 사용하는 이진 파일 형식을 사용한다. .dta 파일에는 데이터, 변수 레이블, 값 레이블 등 메타데이터가 포함되어 있다. .dta 파일은 STATA에서만 읽을 수 있고 SAS, SPSS에서 읽을 수는 없다 하지만, ‘SAS STATA Transfer’ 프로시저를 ’SPSS Data Access Pack’을 구매하여 STATA 파일을 불러읽을 수 있으며, STATA에서 CSV 파일 형태로 내보낸 후 별도 프로시저나 팩없이 SPSS, SAS에서 불러읽을 수 있는 방법이 있다.\n하지만, 통계 패키지 간에 데이터를 교환하려면 일반적으로 .csv(쉼표로 분리된 값) 또는 .txt(탭으로 분리된 값) 형식과 같은 중간 파일 형식을 사용하는 과정에서 변수 레이블과 값 레이블과 같은 일부 메타데이터가 손실될 수 있다.\n따라서, 단기적으로 SAS/SPSS/STATA와 같은 독점 파일 형식이 제공하는 장점보다 개방형 파일 형식이 장기적으로 데이터 접근성과 재사용성을 높일 수 있다는 면에서 장점이 크다.",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>상용 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_spreadsheet.html#통계패키지",
    "href": "ingest_spreadsheet.html#통계패키지",
    "title": "26  상용 데이터",
    "section": "",
    "text": "26.1.1 SPSS\n세종시에 위치한 한국보건사회연구원에서 조사하여 발표하는 한국복지패널데이터는 특이하게도 오픈 파일 형식만 제외하고 상용 통계 패키지가 있어야 열어볼 수 있는 SPSS, STATA, SAS 파일 형식으로 제공되고 있다. 총4가지 종류 파일을 제공하고 있지만 여기서는 다양한 파일 데이터를 불러오는 방법을 중심으로 살펴보기 때문에 가장 단순한 파일만 R 환경으로 불러오는 방법을 살펴보자.\n\n가구용데이터(SAS, SPSS, STATA):koweps_h17_2022_Beta1\n가구원용데이터(SAS, SPSS, STATA):koweps_p17_2022_Beta1\n복지인식설문용데이터(SAS, SPSS, STATA):koweps_wc17_2022_Beta1\n가구용, 가구원용, 복지인식설문용 머지데이터(SAS, SPSS, STATA):koweps_hpwc17_2022_Beta1\n\nSPSS 로 작성된 .sav 파일으로 R 환경으로 불러오기 위해서는 haven 패키지를 로드하여 SPSS (.sav) 데이터 파일을 R로 읽어온다. read_spss() 함수를 사용하여 “koweps_hpwc17_2022_Beta1.sav” 파일을 welfare_raw 데이터 프레임으로 저장한 후, map_chr() 함수를 사용하여 welfare_raw의 각 변수에 대해 attributes(.x)$label을 적용하여 변수의 레이블을 추출하고 후속 작업을 위해서 문자형 벡터로 변환시킨다.\nenframe() 함수를 사용하여 추출된 레이블을 데이터 프레임으로 변환하고, filter() 함수와 str_detect() 함수를 사용하여 “성별”, “종교”, “태어난 연도”, “혼인상태”, “가구원수”라는 키워드가 포함된 변수만 선택한다. pull() 함수를 사용하여 선택된 변수의 이름을 추출하고, setdiff() 함수를 사용하여 정규표현식 작성과정에서 함께 추출된”h1707_6aq6” 변수를 제외시킨 후 demo_vars 변수로 저장한다.\nwelfare_raw 데이터 프레임에서 select() 함수와 all_of() 함수를 사용하여 demo_vars에 해당하는 변수만 선택한 후 set_names() 함수를 사용하여 선택된 변수명을 “성별”, “종교”, “태어난 연도”, “혼인상태”, “가구원수”로 변경한다. str_split()과 dput()을 사용하여 변수 이름을 파이프(|)로 연산으로 한 명령어로 처리한다. janitor 패키지 clean_names() 함수를 사용하여 변수 이름을 깔끔하게 정리하는데, ascii = FALSE 옵션을 사용하여 한글 변수명을 유지한다.\n한국보건사회연구원에서 한국복지패널 데이터가 SPSS로 제공되고 있지만 상용 SPSS 패키지가 없더라도 R 환경에서 haven 패키지와 janitor 패키지를 활용하여 SPSS 데이터를 불러와서 본격적인 분석을 오픈 데이터 분석 및 통계 언어 R로 수행할 준비가 되었다.\n\nlibrary(haven) # install.packages(\"foreign\")\n\n# Read the .sav file\nwelfare_raw &lt;- read_spss(\"data/file/SPSS/koweps_hpwc17_2022_Beta1.sav\")\n\n## 관심 변수 추출\ndemo_vars &lt;- welfare_raw %&gt;%\n  map_chr(~attributes(.x)$label) |&gt; \n    enframe() |&gt; \n    filter(str_detect(value, \"성별|종교|(태어난 연도)|혼인상태|가구원수\")) |&gt; \n    pull(name) |&gt; \n    setdiff(\"h1707_6aq6\") # 기타소비-종교관련비 변수 제거\n\n## 인구통계학적 변수로 구성된 데이터셋\nwelfare_raw %&gt;%\n  select(all_of(demo_vars)) |&gt; \n    set_names(str_split(\"성별|종교|(태어난 연도)|혼인상태|가구원수\", \"\\\\|\")[[1]] |&gt; dput()) |&gt; \n    janitor::clean_names(ascii = FALSE)\n#&gt; c(\"성별\", \"종교\", \"(태어난 연도)\", \"혼인상태\", \"가구원수\"\n#&gt; )\n#&gt; # A tibble: 16,591 × 5\n#&gt;     성별  종교 태어난_연도 혼인상태 가구원수\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1     1     2        1945        2        1\n#&gt;  2     1     1        1948        2        2\n#&gt;  3     1     1        1942        3        1\n#&gt;  4     5     1        1962        1        1\n#&gt;  5     5     2        1963        1        1\n#&gt;  6     5     2        2003        5        1\n#&gt;  7     5     1        1927        1        1\n#&gt;  8     5     2        1934        1        1\n#&gt;  9     1     2        1940        2        1\n#&gt; 10     2     2        1970        3        1\n#&gt; # ℹ 16,581 more rows\n\n\n26.1.2 SAS\nSAS 통계패키지 koweps_hpwc17_2022_beta1.sas7bdat 파일을 작성된 동일한 한국보건사회연구원에서 한국복지패널 데이터도 haven 패키지를 사용하여 read_sas() 함수를 사용하여 SAS 데이터 파일(.sas7bdat)을 불러온다. 이후 코드는 앞서 SPSS 데이터를 R 인구통계 데이터프레임으로 변환시켜 가져온 것과 동일한 방법으로 진행된다. 즉, 코드를 재사용하게 된다.\n\nlibrary(haven) # install.packages(\"foreign\")\n\nsas_raw &lt;- read_sas(\"data/file/SAS/koweps_hpwc17_2022_Beta1.sas7bdat\")\n\n## 관심 변수 추출\nsas_vars &lt;- sas_raw %&gt;%\n  map_chr(~attributes(.x)$label) |&gt;\n  enframe() |&gt;\n  filter(str_detect(value, \"성별|종교|(태어난 연도)|혼인상태|가구원수\")) |&gt;\n  pull(name) |&gt;\n  setdiff(\"h1707_6aq6\") # 기타소비-종교관련비 변수 제거\n\n## 인구통계학적 변수로 구성된 데이터셋\nsas_raw %&gt;%\n  select(all_of(sas_vars)) |&gt;\n  set_names(str_split(\"성별|종교|(태어난 연도)|혼인상태|가구원수\", \"\\\\|\")[[1]] |&gt; dput()) |&gt;\n  janitor::clean_names(ascii = FALSE)\n#&gt; c(\"성별\", \"종교\", \"(태어난 연도)\", \"혼인상태\", \"가구원수\"\n#&gt; )\n#&gt; # A tibble: 16,591 × 5\n#&gt;     성별  종교 태어난_연도 혼인상태 가구원수\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1     1     2        1945        2        1\n#&gt;  2     1     1        1948        2        2\n#&gt;  3     1     1        1942        3        1\n#&gt;  4     5     1        1962        1        1\n#&gt;  5     5     2        1963        1        1\n#&gt;  6     5     2        2003        5        1\n#&gt;  7     5     1        1927        1        1\n#&gt;  8     5     2        1934        1        1\n#&gt;  9     1     2        1940        2        1\n#&gt; 10     2     2        1970        3        1\n#&gt; # ℹ 16,581 more rows\n\n\n26.1.3 STATA\nSTATA 통계패키지 koweps_hpwc17_2022_beta1.dta 파일은 SAS 버전과 동일한 한국복지패널 데이터다. R에서 haven 패키지 read_dta() 함수를 사용하여 STATA 데이터 파일(.dta)을 불러올 수 있다. 이후 코드는 앞서 SPSS, SAS 데이터를 R로 가져와 인구통계 데이터프레임으로 변환한 것과 동일한 방법으로 진행된다. 따라서 이전에 작성한 코드를 그대로 재사용할 수 있다.\n\nlibrary(haven) # install.packages(\"haven\")\n\n# STATA 파일 불러오기\nstata_raw &lt;- read_dta(\"data/file/STATA/Koweps_hpwc17_2022_beta1.dta\")\n\n## 관심 변수 추출\nstata_vars &lt;- stata_raw %&gt;%\n  map_chr(~attributes(.x)$label) |&gt;\n  enframe() |&gt;\n  filter(str_detect(value, \"성별|종교|(태어난 연도)|혼인상태|가구원수\")) |&gt;\n  pull(name) |&gt;\n  setdiff(\"h1707_6aq6\") # 기타소비-종교관련비 변수 제거\n\n## 인구통계학적 변수로 구성된 데이터셋\nstata_raw %&gt;%\n  select(all_of(stata_vars)) |&gt;\n  set_names(str_split(\"성별|종교|(태어난 연도)|혼인상태|가구원수\", \"\\\\|\")[[1]] |&gt; dput()) |&gt;\n  janitor::clean_names(ascii = FALSE)\n#&gt; c(\"성별\", \"종교\", \"(태어난 연도)\", \"혼인상태\", \"가구원수\"\n#&gt; )\n#&gt; # A tibble: 16,591 × 5\n#&gt;     성별  종교 태어난_연도 혼인상태 가구원수\n#&gt;    &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n#&gt;  1     1     2        1945        2        1\n#&gt;  2     1     1        1948        2        2\n#&gt;  3     1     1        1942        3        1\n#&gt;  4     5     1        1962        1        1\n#&gt;  5     5     2        1963        1        1\n#&gt;  6     5     2        2003        5        1\n#&gt;  7     5     1        1927        1        1\n#&gt;  8     5     2        1934        1        1\n#&gt;  9     1     2        1940        2        1\n#&gt; 10     2     2        1970        3        1\n#&gt; # ℹ 16,581 more rows",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>상용 데이터</span>"
    ]
  },
  {
    "objectID": "ingest_spreadsheet.html#엑셀",
    "href": "ingest_spreadsheet.html#엑셀",
    "title": "26  상용 데이터",
    "section": "\n26.2 엑셀",
    "text": "26.2 엑셀",
    "crumbs": [
      "**7부** 가져오기",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>상용 데이터</span>"
    ]
  }
]